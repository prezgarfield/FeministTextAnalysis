{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7: Jupyter Notebook Assignment - Working with Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Student Name: Rob Garfield\n",
    "* Date: 10/22/19\n",
    "* Instructor: Lisa Rhody\n",
    "* Assignment due: 10/22/19\n",
    "* Methods of Text Analysis\n",
    "* MA in DH at The Graduate Center, CUNY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "The purpose of this notebook is to get some hands-on experience putting what you've seen in tutorials about importing and working with text in Python into practice. You'll also be asked to put the reading you've been doing all semester into conversation with the process of importing, cleaning, and preparing data. \n",
    "\n",
    "The object of the notebooks this week is: \n",
    "* To practice several ways of importing text into your Python environment to study; \n",
    "* To become more familiar with various pipelines for cleaning and preparing data for text analysis; \n",
    "* To consider the challenges that the availability and scarcity of data presents to the literary scholar (and to consider how other kinds of research might also need to address similar issues); \n",
    "* To connect examples of real-world text analysis projects with the practical process of cleaning and preparing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n",
    "You've worked with data during the Datacamp exercises, but that was a much more controlled environment. When you are actually doing your own text analysis project, you will have a much messier process. During this week's reading, you will have read several pieces about what cleaning takes place and some of the challenges that data presents when working with text. In particular, we're looking at text analysis from a humanities / litereary perspective; however, one might argue that these challenges are more similar to the text analysis one might perform in the social sciences or with non-fiction work than might appear to be the case on the surface. \n",
    "\n",
    "In this lesson, we'll practice importing data: \n",
    "* from a file already on your computer (using a directory path); \n",
    "* from a file on the web using a URL request \n",
    "* from a file on the web using Beautiful Soup. \n",
    "\n",
    "There are many other ways to collect data, and perhaps some of our time could / should be spent on webscraping in order to collect data. The easiest way to get lots of data is by importing with an API. For those who are looking for a challenge, try importing Movie Reviews from the New York Times via their API for your notebook assignment this week instead. Be sure to use BeautifulSoup to prettify it, and then store the data in a pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from a flat file on your local computer\n",
    "When you downloaded the zip file for this week, included in the folder is a copy of Charlotte Perkins Gilman's _Herland_. During this activity, you will open that file, preview it, manipulate it, and do some cleaning and statistical inquiry. \n",
    "\n",
    "The first thing we're going to do is to import the packages that we may need. Then we're going to use a Python function `open()`. We'll use a `for` loop, which simply means that we'll do an action that repeats until we tell it to stop. The following code says that we want to `open` the file `herland.txt` so we can read it (argument `mode='r'`). Then we're going to close the file. When we do this, we're going to assign a variable name to the resulting data, which is now a string called `file`.\n",
    "\n",
    "###RG -- PLEASE NOTE I HAD TO ADD THE 'ENCODING' PARAMETER TO GET THESE IMPORTS TO WORK CORRECTLY (PYTHON 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "filename = 'herland.txt'\n",
    "herland = open(filename, mode='r', encoding=\"utf-8\")\n",
    "hertext = herland.read()\n",
    "herland.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you print a string from a file without having to close the file using a context manager\n",
    "with open('herland.txt','r', encoding=\"utf-8\") as file:\n",
    "    #print(file.read())\n",
    "    file.read()\n",
    "#RG -- removed print to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of Herland, by Charlotte Perkins Stetson Gilman\n",
      "\n",
      "\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you don't want to save the text of the file, but just want to peek into it to see what's there, you could use this method. \n",
    "\n",
    "with open('herland.txt', encoding=\"utf-8\") as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens when you import a flat file? \n",
    "\n",
    "The python function `type()` will return to you output that explains the data type you are working with. When you pass the new text object `herland` through the `type()` function below, what response do you get? The response will look different from other data types that you've used before. In this case, it is read in as a \"file object.\" Remember that Python won't know how to handle data unless it fits a particular data type that the computer expects when passing a function to it. In the next input, we ask Python for the length of the file. This will throw an error. Why do you think that is? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_io.TextIOWrapper"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# herland is a file object, not a string.\n",
    "type(herland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type '_io.TextIOWrapper' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4105b81e8a20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# since herland is a file object and not a string, you can't find the length of it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mherland\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type '_io.TextIOWrapper' has no len()"
     ]
    }
   ],
   "source": [
    "# since herland is a file object and not a string, you can't find the length of it.\n",
    "len(herland)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response here: \n",
    "\"herland is a file object and not a string\".  the variable needs to be typecast as a string. I did this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We had to go through a process to convert the file object to a string. \n",
    "Looking at the cells below, which variable should return `type()` as a string? (The answer is in the cell below.) \n",
    "\n",
    "RG -- I set it up below to work right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but hertext is a different datatype. How would you check? \n",
    " \n",
    "with open('herland.txt', encoding='utf-8') as file:\n",
    "    hertext=file.read()\n",
    "type(hertext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a string, there are a number of functions that you can make use of. One of those is the `len()` command, which you can run below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315999"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many characters are in the hertext string? \n",
    "len(hertext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once an object is recognized as a string, you can begin manipulating it. For example, you could count the number of times the sequence of characters \"her\" appear within the entire text of _Herland_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1244"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hertext.count('her', 0, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to count characters, words, n-grams, etc. means that we can also more easily target specific sections of the text. For example, when you print to your screen the opening of the herland file, you notice that it is accompanied with metadata. For the purposes of text analysis, what would be the advantages or disadvantages of removing the metadata associated with _Herland_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of Herland, by Charlotte Perkins Stetson Gilman\n",
      "\n",
      "This eBook is for the use of anyone anywhe\n"
     ]
    }
   ],
   "source": [
    "# What is happening at the beginning of the herland.txt file, though? We can check to see by using an index. \n",
    "print(hertext[:120])\n",
    "\n",
    "#RG shortening for presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with a string is *more* helpful than simply working with a text object, but there are other things that we can do to the text to make it more easily manipulated in Python and NLTK. For example, when you're working with a string, it's not easy to count whole words. The NLTK word tokenizer function, however, will take a string and turn it into \"tokens\"--discrete segments of characters. Tokenized strings become a new data type--a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hertokens = nltk.word_tokenize(hertext)\n",
    "type(hertokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tokenized list can be called, acted upon, and manipulated differently than a string. If we call just the tokens that are in index positions 0-15, here is what you would get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Herland',\n",
       " ',',\n",
       " 'by',\n",
       " 'Charlotte',\n",
       " 'Perkins',\n",
       " 'Stetson',\n",
       " 'Gilman',\n",
       " 'This',\n",
       " 'eBook',\n",
       " 'is']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hertokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = nltk.Text(hertokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68494"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that',\n",
       " 'they',\n",
       " 'seemed',\n",
       " 'sure',\n",
       " '.',\n",
       " 'I',\n",
       " 'told',\n",
       " 'the',\n",
       " 'boys',\n",
       " 'about',\n",
       " 'these',\n",
       " 'stories',\n",
       " ',',\n",
       " 'and',\n",
       " 'they',\n",
       " 'laughed',\n",
       " 'at',\n",
       " 'them',\n",
       " '.',\n",
       " 'Naturally',\n",
       " 'I',\n",
       " 'did',\n",
       " 'myself',\n",
       " '.',\n",
       " 'I']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[1000:1025]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "When you import text from a flat file that is saved on your local computer, what will you need to do in order to select parts of the text using an index? \n",
    "\n",
    "RG--\n",
    "1) Turn the file into a string by reading it into a variable.\n",
    "2) use nltk to tokenize the string variable\n",
    "-- note, can index at this point --\n",
    "3) cast the tokenized variable as an nltk text object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we're going to retrieve text directly from a URL with the `urlllib` package\n",
    "To do this, we're going to call the package `urllib` and specifically from that we're going to use `urlretrieve.` Next, we need to assign the text in the file to a variable. In this case, that variable is `url`. We're going to run `urlretrieve` with two parameters, the name of the URL you want to import (which you assigned to the variable `url` above, and the file name and extension. Here that is `203-0.txt.` If you pay attention to the output, you'll realize that you've imported the file as an object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "url = 'https://www.gutenberg.org/files/203/203-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('203-0.txt','r', encoding='utf-8') as file:\n",
    "    uncletom=file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using what you've learned so far, how would you figure out what data type the file `uncletom` is? Add a cell below and show how you would find the answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uncletom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the next 2 cells, print a selection of Uncle Tom's Cabin and the length of it. What else could we do with the text at this point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t swaggering air of pretension\n",
      "which marks a low man who is trying to elbow his way upward in the\n",
      "world. He was much over-dressed, in a gaudy vest of many colors, a blue\n",
      "neckerchief, bedropped gayly w\n"
     ]
    }
   ],
   "source": [
    "print(uncletom[1400:1600])\n",
    "#RG -- making short for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025490"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncletom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing an HTML file using an http: request\n",
    "The previous two files that we imported were _plain text_ files. In other words, there is little to no descriptive encoding. However, we can also use another module from the URLLIB package that is designed to import an .html file directly from the web. We can actually do this with just a few lines of code. First, we import the URLLIB package, and specifically the `request` module. We assign the URL we want to manipulate by assigning the URL to a variable. Next, we pass the URL through the urlopen.request function from the URLLIB package, and also at the same time \"read\" the file. The output of that string becomes the variable `html`. When we print the variable html, we discover that all of the HTML from the page has been pulled into the variable name. Unfortuantely, it doesn't look very clean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import the bibliography page from Colored Conventions in HTML\n",
    "import urllib.request\n",
    "anotherurl='http://coloredconventions.org/exhibits/show/bishophmturner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urllib.request.urlopen(anotherurl).read()\n",
    "#print(html)\n",
    "#RG commenting out print for presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in doing text analysis of a webpage, and the only way to ingest the web page is with HTML included, what are things you might need to learn to do to separate the HTML tags from the text? Look at the code above and write a short description of what might need to stay and what might need to be extracted. Should the extracted data be preserved or discarded? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data by Webscraping with BeautifulSoup\n",
    "If you are interested in scraping data from the open web, BeautifulSoup is a Python pacakge worth exploring in detail. For our purposes here, though, we're going to consider how to use Beautiful Soup to turn \"unstructured\" data into \"structured\" data. As you read through this section, consider Muñoz and Rawson's argument about data cleaning. Is there a need for the data to stay unstructured? What is the value of cleaning? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify url: url\n",
    "url4 = 'http://coloredconventions.org/press#scholarship'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url4)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Prettify the BeautifulSoup object: pretty_soup\n",
    "pretty_soup = soup.prettify()\n",
    "\n",
    "# Print the response\n",
    "#print(pretty_soup)\n",
    "\n",
    "#RG -- commenting out print for presentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the text imported using the \"webscraping\" method included with BeautifulSoup versus the option of importing the entire file using URLLIB. \n",
    "\n",
    "RG-- Soup's prettify function formats the html to be much more readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up Webscraped text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Press &amp; Notices · ColoredConventions.org</title>\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url5 = 'http://coloredconventions.org/press#scholarship'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url5)\n",
    "\n",
    "# Extract the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Get the title of Colored Conventions' webpage: ccc_title\n",
    "ccc_title = soup.title\n",
    "\n",
    "# Print the title of Colored Conventions' webpage to the shell\n",
    "print(ccc_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Colored Conventions' text: ccc_text\n",
    "ccc_text = soup.get_text()\n",
    "\n",
    "# Print CCC's text \n",
    "# print(ccc_text)\n",
    "\n",
    "#RG commenting out print for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/items/search\n",
      "/\n",
      "/conventions\n",
      "/convention-by-year\n",
      "/national-conventions\n",
      "/state-conventions\n",
      "/regional-conventions\n",
      "/conventions-by-region\n",
      "/transcribe-minutes\n",
      "http://coloredconventions.org/hbd\n",
      "http://coloredconventions.org/transcribe-minutes?set=ame\n",
      "http://coloredconventions.org/transcribe-minutes?set=baptist\n",
      "http://coloredconventions.org/intro-corpus\n",
      "/submit-minutes\n",
      "/delegate-search\n",
      "http://coloredconventions.org/exhibits\n",
      "http://coloredconventions.org/introduction-to-movement\n",
      "http://coloredconventions.org/exhibits/show/conventions-black-press\n",
      "http://coloredconventions.org/exhibits/show/1853-manual-labor\n",
      "http://coloredconventions.org/exhibits/show/bishophmturner\n",
      "http://coloredconventions.org/exhibits/show/mobilitymigration1855\n",
      "http://coloredconventions.org/exhibits/show/henry-highland-garnet-address\n",
      "http://coloredconventions.org/exhibits/show/williams-forson-exhibit\n",
      "http://coloredconventions.org/exhibits/show/exhibit-1843\n",
      "http://coloredconventions.org/exhibits/show/womens-economic-power\n",
      "http://coloredconventions.org/exhibits/show/convention-of-1830\n",
      "http://coloredconventions.org/exhibits/show/the-performance-of-convention-\n",
      "http://coloredconventions.org/exhibits/show/national-press-1847\n",
      "http://coloredconventions.org/exhibits/show/black-convention-activism-in-t\n",
      "/exhibits/show/conflict-on-the-ohio\n",
      "http://coloredconventions.org/exhibits/show/postbellumsouthernconventions\n",
      "/maps\n",
      "/city-map-update-2015-11\n",
      "http://coloredconventions.org/neatline/show/national-conventions\n",
      "http://coloredconventions.org/neatline/show/women-delegates\n",
      "/neatline/show/women-conventions-movement\n",
      "/maps#bydenomination\n",
      "http://coloredconventions.org/neatline/show/conventions-at-ame-churches\n",
      "http://coloredconventions.org/neatline/show/baptist-churches-that-hosted-conventions\n",
      "http://coloredconventions.org/neatline/show/presbyterian-churches-that-hosted-conventions\n",
      "/levels\n",
      "/timeline\n",
      "/clusters\n",
      "/canada-networks\n",
      "/women-and-the-conventions-2017\n",
      "/tables\n",
      "/teaching\n",
      "http://coloredconventions.org/partners\n",
      "/curriculum#set\n",
      "http://coloredconventions.org/files/original/d4bb494ee17d485f461886559bac59c2.pdf\n",
      "http://coloredconventions.org/files/original/5c62efa0e78d328cd9e69f6debd02ade.pdf\n",
      "/research-guides\n",
      "/student-memo-of-understanding\n",
      "/memo-of-understanding\n",
      "/ccp-class\n",
      "/bibliography\n",
      "/press#scholarship\n",
      "/ccncda\n",
      "http://coloredconventions.org/symposium-participants\n",
      "http://coloredconventions.org/ccncda\n",
      "/symposium-participants\n",
      "/symposium-abstracts\n",
      "/cfp-colored-conventions-in-the-nineteenth-century-and-the-digital-age\n",
      "/symposium-tweets\n",
      "/schedule\n",
      "/hbd\n",
      "/douglass-kit\n",
      "/hbd-2017\n",
      "/hbd-2018\n",
      "/douglass-day-2018-locations\n",
      "/douglass-kit-2018\n",
      "/outreach-guide-2018\n",
      "/fdday-2019-faq\n",
      "/douglass-kit-2019\n",
      "/about-us\n",
      "http://coloredconventions.org/about-us\n",
      "/clir-fellows\n",
      "/project-videos\n",
      "/partners\n",
      "/press\n",
      "/ccp-principles\n",
      "/project-cv\n",
      "mailto:coloredconventions@udel.edu\n",
      "https://udapps.nss.udel.edu/makeagift/?appealCode=16AKT\n",
      "/\n",
      "/conventions\n",
      "/convention-by-year\n",
      "/national-conventions\n",
      "/state-conventions\n",
      "/regional-conventions\n",
      "/conventions-by-region\n",
      "/transcribe-minutes\n",
      "http://coloredconventions.org/hbd\n",
      "http://coloredconventions.org/transcribe-minutes?set=ame\n",
      "http://coloredconventions.org/transcribe-minutes?set=baptist\n",
      "http://coloredconventions.org/intro-corpus\n",
      "/submit-minutes\n",
      "/delegate-search\n",
      "http://coloredconventions.org/exhibits\n",
      "http://coloredconventions.org/introduction-to-movement\n",
      "http://coloredconventions.org/exhibits/show/conventions-black-press\n",
      "http://coloredconventions.org/exhibits/show/1853-manual-labor\n",
      "http://coloredconventions.org/exhibits/show/bishophmturner\n",
      "http://coloredconventions.org/exhibits/show/mobilitymigration1855\n",
      "http://coloredconventions.org/exhibits/show/henry-highland-garnet-address\n",
      "http://coloredconventions.org/exhibits/show/williams-forson-exhibit\n",
      "http://coloredconventions.org/exhibits/show/exhibit-1843\n",
      "http://coloredconventions.org/exhibits/show/womens-economic-power\n",
      "http://coloredconventions.org/exhibits/show/convention-of-1830\n",
      "http://coloredconventions.org/exhibits/show/the-performance-of-convention-\n",
      "http://coloredconventions.org/exhibits/show/national-press-1847\n",
      "http://coloredconventions.org/exhibits/show/black-convention-activism-in-t\n",
      "/exhibits/show/conflict-on-the-ohio\n",
      "http://coloredconventions.org/exhibits/show/postbellumsouthernconventions\n",
      "/maps\n",
      "/city-map-update-2015-11\n",
      "http://coloredconventions.org/neatline/show/national-conventions\n",
      "http://coloredconventions.org/neatline/show/women-delegates\n",
      "/neatline/show/women-conventions-movement\n",
      "/maps#bydenomination\n",
      "http://coloredconventions.org/neatline/show/conventions-at-ame-churches\n",
      "http://coloredconventions.org/neatline/show/baptist-churches-that-hosted-conventions\n",
      "http://coloredconventions.org/neatline/show/presbyterian-churches-that-hosted-conventions\n",
      "/levels\n",
      "/timeline\n",
      "/clusters\n",
      "/canada-networks\n",
      "/women-and-the-conventions-2017\n",
      "/tables\n",
      "/teaching\n",
      "http://coloredconventions.org/partners\n",
      "/curriculum#set\n",
      "http://coloredconventions.org/files/original/d4bb494ee17d485f461886559bac59c2.pdf\n",
      "http://coloredconventions.org/files/original/5c62efa0e78d328cd9e69f6debd02ade.pdf\n",
      "/research-guides\n",
      "/student-memo-of-understanding\n",
      "/memo-of-understanding\n",
      "/ccp-class\n",
      "/bibliography\n",
      "/press#scholarship\n",
      "/ccncda\n",
      "http://coloredconventions.org/symposium-participants\n",
      "http://coloredconventions.org/ccncda\n",
      "/symposium-participants\n",
      "/symposium-abstracts\n",
      "/cfp-colored-conventions-in-the-nineteenth-century-and-the-digital-age\n",
      "/symposium-tweets\n",
      "/schedule\n",
      "/hbd\n",
      "/douglass-kit\n",
      "/hbd-2017\n",
      "/hbd-2018\n",
      "/douglass-day-2018-locations\n",
      "/douglass-kit-2018\n",
      "/outreach-guide-2018\n",
      "/fdday-2019-faq\n",
      "/douglass-kit-2019\n",
      "/about-us\n",
      "http://coloredconventions.org/about-us\n",
      "/clir-fellows\n",
      "/project-videos\n",
      "/partners\n",
      "/press\n",
      "/ccp-principles\n",
      "/project-cv\n",
      "mailto:coloredconventions@udel.edu\n",
      "https://udapps.nss.udel.edu/makeagift/?appealCode=16AKT\n",
      "http://coloredconventions.org\n",
      "/\n",
      "/about-us\n",
      "None\n",
      "http://muse.jhu.edu/journals/american_periodicals/v026/26.1.fagan.html\n",
      "http://muse.jhu.edu/login?auth=0&type=summary&url=/journals/early_american_literature/v051/51.1.spires.html\n",
      "https://muse.jhu.edu/login?auth=0&type=summary&url=/journals/american_periodicals/v025/25.2.gardner01.html\n",
      "https://muse.jhu.edu/article/593047\n",
      "http://common-place.org/article/column/colored-conventions-project/\n",
      "http://common-place.org/book/the-colored-conventions-project-and-the-changing-same/\n",
      "http://common-place.org/book/toward-meaning-making-in-the-digital-age-black-women-black-data-and-colored-conventions/\n",
      "http://common-place.org/book/the-colored-conventions-movement-in-print-and-beyond/\n",
      "http://common-place.org/book/convention-minutes-and-unconventional-proceedings/\n",
      "http://common-place.org/book/liberating-history-reflections-on-rights-rituals-and-the-colored-conventions-project/\n",
      "http://digitalhumanitiesnow.org/2016/03/digital-rudisell-of-the-colored-conventions-project-on-copyright-and-doing-digital-black-history/\n",
      "https://www.museumarchipelago.com/57\n",
      "https://dmlcentral.net/digitally-improving-historical-knowledge/\n",
      "https://www.forbes.com/sites/drsarahbond/2017/10/20/how-is-digital-mapping-changing-the-way-we-visualize-racism-and-segregation/\n",
      "https://www.brown.edu/academics/public-humanities/news/2017-02/put-it-digital-writing-transcribing-amazing-jobs-frederick-douglass-colored-conventio-0%20\n",
      "http://www.delawareonline.com/story/news/education/2017/02/15/ud-group-celebrates-frederick-douglass-birthday/97948962/\n",
      "http://technical.ly/delaware/2016/12/13/colored-conventions-project-mla-award/\n",
      "http://www1.udel.edu/udmessenger/vol24no3/digital/vol24no3/index.html#p=20\n",
      "http://blog.historians.org/2016/12/uncovering-activism-engaging-students-colored-conventions-project/\n",
      "http://www.phillytrib.com/commentary/resurrect-philly-s-black-economic-educational-activism/article_27c207d4-c8e0-5f3a-87e9-67ee3cf9dbce.html\n",
      "http://www.nytimes.com/2016/08/05/arts/design/colored-conventions-a-rallying-point-for-black-americans-before-the-civil-war.html?_r=0\n",
      "http://www.slate.com/blogs/the_vault/2015/12/21/some_neat_new_digital_history_projects_that_were_new_in_2015.html\n",
      "http://blogs.loc.gov/digitalpreservation/2015/09/cultural-institutions-embrace-crowdsourcing/\n",
      "http://www.electrostani.com/2015/09/the-archive-gap-race-canon-and-digital.html\n",
      "http://delawarepublic.org/post/history-matters-colored-conventions\n",
      "https://slis.wisc.edu/wp-content/uploads/2016/02/2015_spring_jottings.pdf\n",
      "http://www.thefacultylounge.org/2015/03/black-originalism-part-3-the-syracuse-convention-of-1864.html\n",
      "http://infospace.ischool.syr.edu/2015/02/19/crowd-sourced-project-19th-century-colored-conventions/\n",
      "http://blackpressresearchcollective.org/2015/01/31/colored-conventions-and-the-early-black-press-by-benjamin-fagan/\n",
      "http://www.theroot.com/articles/history/2014/03/joining_the_dar_a_guide_for_americans_of_all_races.html\n",
      "http://www.udel.edu/udaily/2017/february/frederick-douglass-historical-records-transcription/\n",
      "http://www.udel.edu/udaily/2016/december/mla-award-colored-conventions-project/\n",
      "http://www1.udel.edu/udaily/2016/may/colored-conventions-accessible-archives-051116.html\n",
      "http://www1.udel.edu/udaily/2016/apr/neh-colored-conventions-041416.html\n",
      "http://www.udel.edu/udaily/2016/sep/library-agreement-090315.html\n",
      "http://www1.udel.edu/udaily/2015/apr/colored-conventions-042015.html\n",
      "http://www1.udel.edu/udaily/2015/mar/transcribe-minutes-031015.html\n",
      "http://www.lib.udel.edu\n",
      "http://www.udel.edu/ihrc/\n",
      "http://www.neh.gov\n",
      "/\n",
      "/conventions\n",
      "http://coloredconventions.org/exhibits\n",
      "/teaching\n",
      "/bibliography\n",
      "/ccncda\n",
      "/hbd\n",
      "/about-us\n",
      "mailto:coloredconventions@udel.edu\n",
      "https://www.facebook.com/ColoredConventionsProject/\n",
      "https://twitter.com/CCP_org\n",
      "https://www.instagram.com/colored_conventions/\n",
      "http://creativecommons.org/licenses/by-nc-sa/4.0/\n",
      "http://creativecommons.org/licenses/by-nc-sa/4.0/\n",
      "http://omeka.org\n",
      "/admin\n"
     ]
    }
   ],
   "source": [
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what the value is of importing HTML files using BeautifulSoup. How does this relate to the concerns that Rawson and Muñoz raise in their article? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soup gives easy access to all the html tags for manipulation and parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access data using an API\n",
    "In the following exercise, you will import data from the Chronicling America API. You will set parameters for what content and keywords to pull in, then you will send the request to the server. After you import the data, you'll organize and clean up the JSON format--in other words, when you get your search results, it will come packaged in a file format, called JSON. We will ingest the JSON file, turn it into a dictionary, and then turn part of that dictionary into a Pandas Dataframe. All we're doing when we turn text data into a dataframe is organizing the metadata and the files into a format that can be used and acted upon in order to do other kinds of analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the Requests module available\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called 'api_search_url' and give it a value\n",
    "api_search_url = 'https://chroniclingamerica.loc.gov/search/pages/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a dictionary called 'params' and sets values for the API's mandatory parameters\n",
    "params = {\n",
    "    'proxtext': 'fiction' # Search for this keyword -- feel free to change!\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Later on, you will be asked to return to the above cell and change the search parameters. You do this by replacing `poetry` with `yourterm`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'proxtext': 'fiction', 'format': 'json'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This adds a value for 'encoding' to our dictionary\n",
    "params['format'] = 'json'\n",
    "\n",
    "# Let's view the updated dictionary\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the formatted url that gets sent to the ChronAmerca API:\n",
      "https://chroniclingamerica.loc.gov/search/pages/results/?proxtext=fiction&format=json\n",
      "\n",
      "All ok\n"
     ]
    }
   ],
   "source": [
    "# This sends our request to the API and stores the result in a variable called 'response'\n",
    "response = requests.get(api_search_url, params=params)\n",
    "\n",
    "# This shows us the url that's sent to the API\n",
    "print('Here\\'s the formatted url that gets sent to the ChronAmerca API:\\n{}\\n'.format(response.url)) \n",
    "\n",
    "# This checks the status code of the response to make sure there were no errors\n",
    "if response.status_code == requests.codes.ok:\n",
    "    print('All ok')\n",
    "elif response.status_code == 403:\n",
    "    print('There was an authentication error. Did you paste your API above?')\n",
    "else:\n",
    "    print('There was a problem. Error code: {}'.format(response.status_code))\n",
    "    print('Try running this cell again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the API's JSON results and make them available as a Python variable called 'data'\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's prettify the raw JSON data and then display it.\n",
    "\n",
    "# We're using the Pygments library to add some colour to the output, so we need to import it\n",
    "import json\n",
    "from pygments import highlight, lexers, formatters\n",
    "\n",
    "# This uses Python's JSON module to output the results as nicely indented text\n",
    "formatted_data = json.dumps(data, indent=2)\n",
    "\n",
    "# This colours the text\n",
    "highlighted_data = highlight(formatted_data, lexers.JsonLexer(), formatters.TerminalFormatter())\n",
    "\n",
    "# And now display the results\n",
    "# print(highlighted_data)\n",
    "\n",
    "#RG -- commented out the print function to remove the huge file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the above cell will be quite long. Before turning in this assignment, please delete the cell above so the file you turn in is not difficult to read. Thank you!\n",
    "\n",
    "RG -- commented out print function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of data type is `outfile`?\n",
    "\n",
    "RG--I don't see an 'outfile' variable, so the next block is throwing an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-3e3870a31e13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'outfile' is not defined"
     ]
    }
   ],
   "source": [
    "print(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(highlighted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the API's JSON results and make them available as a Python variable called 'data'\n",
    "data = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we will take the nested dictionary, which is also a json format, and we will convert it into a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalItems</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>itemsPerPage</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 1, 'county': ['San Francisco'], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 1, 'county': ['San Francisco'], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 84, 'county': [None], 'edition': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 113, 'county': [None], 'edition':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 76, 'county': [None], 'edition': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 112, 'county': [None], 'edition':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 1, 'county': ['Cook County'], 'ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 71, 'county': [None], 'edition': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 44, 'county': ['New York'], 'edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 26, 'county': ['Hartford'], 'edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 12, 'county': ['Hartford'], 'edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 15, 'county': ['Philadelphia'], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 78, 'county': [None], 'edition': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 9, 'county': ['Ohio'], 'edition':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 11, 'county': ['Shelby'], 'editio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 44, 'county': ['New York'], 'edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 140, 'county': [None], 'edition':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 80, 'county': [None], 'edition': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 22, 'county': ['Douglas'], 'editi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 83, 'county': [None], 'edition': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    totalItems  endIndex  startIndex  itemsPerPage  \\\n",
       "0       348002        20           1            20   \n",
       "1       348002        20           1            20   \n",
       "2       348002        20           1            20   \n",
       "3       348002        20           1            20   \n",
       "4       348002        20           1            20   \n",
       "5       348002        20           1            20   \n",
       "6       348002        20           1            20   \n",
       "7       348002        20           1            20   \n",
       "8       348002        20           1            20   \n",
       "9       348002        20           1            20   \n",
       "10      348002        20           1            20   \n",
       "11      348002        20           1            20   \n",
       "12      348002        20           1            20   \n",
       "13      348002        20           1            20   \n",
       "14      348002        20           1            20   \n",
       "15      348002        20           1            20   \n",
       "16      348002        20           1            20   \n",
       "17      348002        20           1            20   \n",
       "18      348002        20           1            20   \n",
       "19      348002        20           1            20   \n",
       "\n",
       "                                                items  \n",
       "0   {'sequence': 1, 'county': ['San Francisco'], '...  \n",
       "1   {'sequence': 1, 'county': ['San Francisco'], '...  \n",
       "2   {'sequence': 84, 'county': [None], 'edition': ...  \n",
       "3   {'sequence': 113, 'county': [None], 'edition':...  \n",
       "4   {'sequence': 76, 'county': [None], 'edition': ...  \n",
       "5   {'sequence': 112, 'county': [None], 'edition':...  \n",
       "6   {'sequence': 1, 'county': ['Cook County'], 'ed...  \n",
       "7   {'sequence': 71, 'county': [None], 'edition': ...  \n",
       "8   {'sequence': 44, 'county': ['New York'], 'edit...  \n",
       "9   {'sequence': 26, 'county': ['Hartford'], 'edit...  \n",
       "10  {'sequence': 12, 'county': ['Hartford'], 'edit...  \n",
       "11  {'sequence': 15, 'county': ['Philadelphia'], '...  \n",
       "12  {'sequence': 78, 'county': [None], 'edition': ...  \n",
       "13  {'sequence': 9, 'county': ['Ohio'], 'edition':...  \n",
       "14  {'sequence': 11, 'county': ['Shelby'], 'editio...  \n",
       "15  {'sequence': 44, 'county': ['New York'], 'edit...  \n",
       "16  {'sequence': 140, 'county': [None], 'edition':...  \n",
       "17  {'sequence': 80, 'county': [None], 'edition': ...  \n",
       "18  {'sequence': 22, 'county': ['Douglas'], 'editi...  \n",
       "19  {'sequence': 83, 'county': [None], 'edition': ...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that a lot of the cells repeat the same data over and over again. What do you think is showing up in each row and column? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>totalItems</th>\n",
       "      <td>348002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>endIndex</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>startIndex</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemsPerPage</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>items</th>\n",
       "      <td>[{'sequence': 1, 'county': ['San Francisco'], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              0\n",
       "totalItems                                               348002\n",
       "endIndex                                                     20\n",
       "startIndex                                                    1\n",
       "itemsPerPage                                                 20\n",
       "items         [{'sequence': 1, 'county': ['San Francisco'], ..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(data, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we switch the layout of the dataframe, it becomes easier to see how the labels for the dataframe are different from the many items in the items observation. We can try to use the json method `normalize` to flatten out the file into columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['endIndex', 'items', 'itemsPerPage', 'startIndex', 'totalItems'], dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.io.json.json_normalize(data)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use the Multi Index function, we essentially collapse all the lists in the dataframe into one observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>endIndex</th>\n",
       "      <th>items</th>\n",
       "      <th>itemsPerPage</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>totalItems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>[{'sequence': 1, 'county': ['San Francisco'], ...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>348002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  endIndex                                              items itemsPerPage  \\\n",
       "0       20  [{'sequence': 1, 'county': ['San Francisco'], ...           20   \n",
       "\n",
       "  startIndex totalItems  \n",
       "0          1     348002  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = pd.MultiIndex.from_tuples([tuple(c.split('.')) for c in df.columns])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "json=pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we name the dataframe json, we can run a miniature program over that file that returns the keys (index labels) of each item in the dictionary `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalItems\n",
      "endIndex\n",
      "startIndex\n",
      "itemsPerPage\n",
      "items\n"
     ]
    }
   ],
   "source": [
    "for key in json:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.tail()` method will print out just the last (in this case) 6 items in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalItems</th>\n",
       "      <th>endIndex</th>\n",
       "      <th>startIndex</th>\n",
       "      <th>itemsPerPage</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 11, 'county': ['Shelby'], 'editio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 44, 'county': ['New York'], 'edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 140, 'county': [None], 'edition':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 80, 'county': [None], 'edition': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 22, 'county': ['Douglas'], 'editi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>348002</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'sequence': 83, 'county': [None], 'edition': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    totalItems  endIndex  startIndex  itemsPerPage  \\\n",
       "14      348002        20           1            20   \n",
       "15      348002        20           1            20   \n",
       "16      348002        20           1            20   \n",
       "17      348002        20           1            20   \n",
       "18      348002        20           1            20   \n",
       "19      348002        20           1            20   \n",
       "\n",
       "                                                items  \n",
       "14  {'sequence': 11, 'county': ['Shelby'], 'editio...  \n",
       "15  {'sequence': 44, 'county': ['New York'], 'edit...  \n",
       "16  {'sequence': 140, 'county': [None], 'edition':...  \n",
       "17  {'sequence': 80, 'county': [None], 'edition': ...  \n",
       "18  {'sequence': 22, 'county': ['Douglas'], 'editi...  \n",
       "19  {'sequence': 83, 'county': [None], 'edition': ...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape()` method will show how many rows and how many columns are in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have lots of differently shaped data objects now. Let's see what the differences are. In the first case, if we take the variable `json` which is a json object and we print `items`, we get a json object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     {'sequence': 1, 'county': ['San Francisco'], '...\n",
      "1     {'sequence': 1, 'county': ['San Francisco'], '...\n",
      "2     {'sequence': 84, 'county': [None], 'edition': ...\n",
      "3     {'sequence': 113, 'county': [None], 'edition':...\n",
      "4     {'sequence': 76, 'county': [None], 'edition': ...\n",
      "5     {'sequence': 112, 'county': [None], 'edition':...\n",
      "6     {'sequence': 1, 'county': ['Cook County'], 'ed...\n",
      "7     {'sequence': 71, 'county': [None], 'edition': ...\n",
      "8     {'sequence': 44, 'county': ['New York'], 'edit...\n",
      "9     {'sequence': 26, 'county': ['Hartford'], 'edit...\n",
      "10    {'sequence': 12, 'county': ['Hartford'], 'edit...\n",
      "11    {'sequence': 15, 'county': ['Philadelphia'], '...\n",
      "12    {'sequence': 78, 'county': [None], 'edition': ...\n",
      "13    {'sequence': 9, 'county': ['Ohio'], 'edition':...\n",
      "14    {'sequence': 11, 'county': ['Shelby'], 'editio...\n",
      "15    {'sequence': 44, 'county': ['New York'], 'edit...\n",
      "16    {'sequence': 140, 'county': [None], 'edition':...\n",
      "17    {'sequence': 80, 'county': [None], 'edition': ...\n",
      "18    {'sequence': 22, 'county': ['Douglas'], 'editi...\n",
      "19    {'sequence': 83, 'county': [None], 'edition': ...\n",
      "Name: items, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(json['items'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we request the data type of `data` we get a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'totalItems': 348002, 'endIndex': 20, 'startIndex': 1, 'itemsPerPage': 20, 'items': [{'sequence': 1, 'county': ['San Francisco'], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn85066387/1904-12-18/ed-1/seq-1/', 'subject': ['California--San Francisco Bay Area.--fast--(OCoLC)fst01242397', 'California--San Francisco.--fast--(OCoLC)fst01204481', 'San Francisco (Calif.)--Newspapers.', 'San Francisco Bay Area (Calif.)--Newspapers.'], 'city': ['San Francisco'], 'date': '19041218', 'title': 'The San Francisco call. [volume]', 'end_year': 1913, 'note': ['\"San Francisco\" appears above, and later across, masthead ornament.', 'Also issued online.', 'Archived issues are available in digital format from the Library of Congress Chronicling America online collection.', 'Issued with a joint ed. of the San Francisco chronicle and the San Francisco examiner on the day after the San Francisco earthquake, Apr. 19, 1906.', 'Master negatives are available for duplication from:', 'Publishers: Charles M. Shortridge, <1896>; John D. Spreckles, <1899>.'], 'state': ['California'], 'section_label': '', 'type': 'page', 'place_of_publication': 'San Francisco [Calif.]', 'start_year': 1895, 'edition_label': '', 'publisher': 'Charles M. Shortridge', 'language': ['English'], 'alt_title': ['Call', 'Call-chronicle-examiner', 'Sunday call'], 'lccn': 'sn85066387', 'country': 'California', 'ocr_eng': 'The Sunday Call Christmas Fiction', 'batch': 'curiv_quincy_ver01', 'title_normal': 'san francisco call.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn85066387/1904-12-18/ed-1/seq-1.json', 'place': ['California--San Francisco--San Francisco'], 'page': '1'}, {'sequence': 1, 'county': ['San Francisco'], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn85066387/1903-12-27/ed-1/seq-1/', 'subject': ['California--San Francisco Bay Area.--fast--(OCoLC)fst01242397', 'California--San Francisco.--fast--(OCoLC)fst01204481', 'San Francisco (Calif.)--Newspapers.', 'San Francisco Bay Area (Calif.)--Newspapers.'], 'city': ['San Francisco'], 'date': '19031227', 'title': 'The San Francisco call. [volume]', 'end_year': 1913, 'note': ['\"San Francisco\" appears above, and later across, masthead ornament.', 'Also issued online.', 'Archived issues are available in digital format from the Library of Congress Chronicling America online collection.', 'Issued with a joint ed. of the San Francisco chronicle and the San Francisco examiner on the day after the San Francisco earthquake, Apr. 19, 1906.', 'Master negatives are available for duplication from:', 'Publishers: Charles M. Shortridge, <1896>; John D. Spreckles, <1899>.'], 'state': ['California'], 'section_label': '', 'type': 'page', 'place_of_publication': 'San Francisco [Calif.]', 'start_year': 1895, 'edition_label': '', 'publisher': 'Charles M. Shortridge', 'language': ['English'], 'alt_title': ['Call', 'Call-chronicle-examiner', 'Sunday call'], 'lccn': 'sn85066387', 'country': 'California', 'ocr_eng': 'Sunday Call Magazine\\nFiction Section', 'batch': 'curiv_darwin_ver01', 'title_normal': 'san francisco call.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn85066387/1903-12-27/ed-1/seq-1.json', 'place': ['California--San Francisco--San Francisco'], 'page': ''}, {'sequence': 84, 'county': [None], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83045462/1941-11-23/ed-1/seq-84/', 'subject': ['Washington (D.C.)--fast--(OCoLC)fst01204505', 'Washington (D.C.)--Newspapers.'], 'city': ['Washington'], 'date': '19411123', 'title': 'Evening star. [volume]', 'end_year': 1972, 'note': ['\"From April 25 through May 24, 1861 one sheet issues were published intermittently owing to scarcity of paper.\" Cf. Library of Congress, Photoduplication Service.', 'Also issued on microfilm from Microfilming Corp. of America and the Library of Congress, Photoduplication Service.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Publisher varies: Noyes, Baker & Co., <1867>; Evening Star Newspaper Co., <1868->', \"Suspended Jan. 1-6, 1971 because of a machinists' strike.\"], 'state': ['District of Columbia'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Washington, D.C.', 'start_year': 1854, 'edition_label': '', 'publisher': 'W.D. Wallach & Hope', 'language': ['English'], 'alt_title': ['Star', 'Sunday star'], 'lccn': 'sn83045462', 'country': 'District of Columbia', 'ocr_eng': 'J&uuttoy Jlfetf\\nWASHINGTON, D. C.\\nNOVEMBEB 23, 1\\n&\\n★\\nFICTION\\nMcGarry Hits the\\nLine in a Riotous\\nFootball\\nI\\nI\\nHow to Male*\\nDouble-Feature\\nBaby Pictures\\nPLUS |. .\\nSAorf Fiction\\nShort Articles\\nFood\\nBeauty\\nCartoons', 'batch': 'dlc_1tatlin_ver01', 'title_normal': 'evening star.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045462/1941-11-23/ed-1/seq-84.json', 'place': ['District of Columbia--Washington'], 'page': ''}, {'sequence': 113, 'county': [None], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83045462/1938-12-18/ed-1/seq-113/', 'subject': ['Washington (D.C.)--fast--(OCoLC)fst01204505', 'Washington (D.C.)--Newspapers.'], 'city': ['Washington'], 'date': '19381218', 'title': 'Evening star. [volume]', 'end_year': 1972, 'note': ['\"From April 25 through May 24, 1861 one sheet issues were published intermittently owing to scarcity of paper.\" Cf. Library of Congress, Photoduplication Service.', 'Also issued on microfilm from Microfilming Corp. of America and the Library of Congress, Photoduplication Service.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Publisher varies: Noyes, Baker & Co., <1867>; Evening Star Newspaper Co., <1868->', \"Suspended Jan. 1-6, 1971 because of a machinists' strike.\"], 'state': ['District of Columbia'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Washington, D.C.', 'start_year': 1854, 'edition_label': '', 'publisher': 'W.D. Wallach & Hope', 'language': ['English'], 'alt_title': ['Star', 'Sunday star'], 'lccn': 'sn83045462', 'country': 'District of Columbia', 'ocr_eng': 'SECTION\\nfftlK Jinucbty Jitaf\\nWASHINGTON. D. C.\\nDECEMBER 18, 1938\\n\"FICTION, ESPECIALLY WHEN\\nIT DEALS WITH TODAY,\\nIS OFTEN TRUER THAN\\nWHAT PASSES FOR FACT\"\\n*\\nRead THE FOURTH DOOR..Page4', 'batch': 'dlc_1miro_ver02', 'title_normal': 'evening star.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045462/1938-12-18/ed-1/seq-113.json', 'place': ['District of Columbia--Washington'], 'page': ''}, {'sequence': 76, 'county': [None], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83045462/1948-08-01/ed-1/seq-76/', 'subject': ['Washington (D.C.)--fast--(OCoLC)fst01204505', 'Washington (D.C.)--Newspapers.'], 'city': ['Washington'], 'date': '19480801', 'title': 'Evening star. [volume]', 'end_year': 1972, 'note': ['\"From April 25 through May 24, 1861 one sheet issues were published intermittently owing to scarcity of paper.\" Cf. Library of Congress, Photoduplication Service.', 'Also issued on microfilm from Microfilming Corp. of America and the Library of Congress, Photoduplication Service.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Publisher varies: Noyes, Baker & Co., <1867>; Evening Star Newspaper Co., <1868->', \"Suspended Jan. 1-6, 1971 because of a machinists' strike.\"], 'state': ['District of Columbia'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Washington, D.C.', 'start_year': 1854, 'edition_label': '', 'publisher': 'W.D. Wallach & Hope', 'language': ['English'], 'alt_title': ['Star', 'Sunday star'], 'lccn': 'sn83045462', 'country': 'District of Columbia', 'ocr_eng': 'WASHINGTON, D. C.\\nMAGAZINE SECTION\\nAUGUST- I 1948\\nIn This Issue:\\nARTICLES • NIMOR\\nFICTION\\nDEAN STOCKWELL (ABOVE) IN A STORY THAT CAME TO LIFE:\\nTHE BOY WITH GREEN HAIR\\n. . . Page 12', 'batch': 'dlc_2feininger_ver01', 'title_normal': 'evening star.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045462/1948-08-01/ed-1/seq-76.json', 'place': ['District of Columbia--Washington'], 'page': ''}, {'sequence': 112, 'county': [None], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83045462/1950-04-23/ed-1/seq-112/', 'subject': ['Washington (D.C.)--fast--(OCoLC)fst01204505', 'Washington (D.C.)--Newspapers.'], 'city': ['Washington'], 'date': '19500423', 'title': 'Evening star. [volume]', 'end_year': 1972, 'note': ['\"From April 25 through May 24, 1861 one sheet issues were published intermittently owing to scarcity of paper.\" Cf. Library of Congress, Photoduplication Service.', 'Also issued on microfilm from Microfilming Corp. of America and the Library of Congress, Photoduplication Service.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Publisher varies: Noyes, Baker & Co., <1867>; Evening Star Newspaper Co., <1868->', \"Suspended Jan. 1-6, 1971 because of a machinists' strike.\"], 'state': ['District of Columbia'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Washington, D.C.', 'start_year': 1854, 'edition_label': '', 'publisher': 'W.D. Wallach & Hope', 'language': ['English'], 'alt_title': ['Star', 'Sunday star'], 'lccn': 'sn83045462', 'country': 'District of Columbia', 'ocr_eng': \"This Week\\nMAGAZINE\\nfhmflay ptaf\\nWASHINGTON, D. C\\nMAGAZINE SECTION • * APRIL 23 1950\\nMEN ON THE MOON: IS IT FACT OR FICTION? SEE PAGE 18\\n“LOVE IN THE WEATHER BUREAU '...»,\", 'batch': 'dlc_2kandinsky_ver01', 'title_normal': 'evening star.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045462/1950-04-23/ed-1/seq-112.json', 'place': ['District of Columbia--Washington'], 'page': ''}, {'sequence': 1, 'county': ['Cook County'], 'edition': None, 'frequency': 'Daily (except Sunday and holidays)', 'id': '/lccn/sn83045487/1912-03-07/ed-1/seq-1/', 'subject': ['Chicago (Ill.)--Newspapers.', 'Illinois--Chicago.--fast--(OCoLC)fst01204048'], 'city': ['Chicago'], 'date': '19120307', 'title': 'The day book. [volume]', 'end_year': 1917, 'note': ['\"An adless daily newspaper.\"', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Available on microfilm;', 'Description based on: Nov. 1, 1911.', 'Issue for <Nov. 24, 1911> lacks vol., no., and chronological designation.', 'Issue for Nov. 4, 1911 erroneously designated as Oct. 4, 1911.', 'Issue for v. 3, no. 290 (Sept. 7, 1914) erroneously designated as v. 3, no. 300 (Sept. 7, 1914). The error in numbering continues.', 'Issue for v. 5, no. 214 (June 7, 1916) erroneously designated as v. 5, no. 214 (June 6, 1916).', 'Issue for v. 5, no. 7 (Oct. 5, 1915) erroneously designated as v. 5, no. 7 (Sept. 5, 1915).', 'Issues for <May 7-17, 1915> called also \"Moving Picture Edition.\"', 'Issues have no page numbering.', 'Saturdays have Noon and Final editions, Dec. 28, 1912-June 21, 1913; Saturdays have Noon and Last editions, June 28, 1913-<Dec. 13, 1913>; began issuing daily Noon and Last editions, Dec. 20, 1913-July 6, 1917.', 'Vol. 5, no. 36 (Nov. 6, 1915) issue called also \"Garment Workers\\' Special Edition.\"', 'Volume numbering begins with Nov. 20, 1911 issue.'], 'state': ['Illinois'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Chicago, Ill.', 'start_year': 1911, 'edition_label': '', 'publisher': 'N.D. Cochran', 'language': ['English'], 'alt_title': [], 'lccn': 'sn83045487', 'country': 'Illinois', 'ocr_eng': 'DR. WILEY, FOOD EXPERT? COMPARES \\'BUTTER\\nAND LARD, IN TODAY\\'S DAY BOOK r\"\\nTHE\\nDAY\\nBOOK\\n500 SO. PEORIA-\\' ST, . 398\\nTEL. Iff ONROE 353\\nVol. 1, No. 139 Chicago; Thursday,;March-7;;i912 . . One Cent\\n\\')\\'$:., ,\\'\\nA STORY STRANGER f HAN\" FICTION THAT\\nSTARTLED ALL OF-.EUROPE .\\n$$ . - - -\\n- , t \\' \\' \\' .\\nThe Blind\\' Girl Cured As \\'By, a\\' Miracle.\\n(Editor\\'s - Note :) This \"story;,\\nis stranger than fiction. Maybe\\npart of it is fiction. -But\" London\\nnewspapers spent ,day.s jnvestU\\ngating this,yourigt woman\\'s storyi\\ncThey.fouhd that-she. was upon\\nthe\\'verge-Qf\\'the grave; and. that\\n;shg jipwJspptlye.They)\\n- J - \" - - .-.J. I iim i r tJiiWii w gii\\niMttMiikMMiyyMMuuMrikkaMiaA', 'batch': 'iune_echo_ver01', 'title_normal': 'day book.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045487/1912-03-07/ed-1/seq-1.json', 'place': ['Illinois--Cook County--Chicago'], 'page': ''}, {'sequence': 71, 'county': [None], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83045462/1935-07-28/ed-1/seq-71/', 'subject': ['Washington (D.C.)--fast--(OCoLC)fst01204505', 'Washington (D.C.)--Newspapers.'], 'city': ['Washington'], 'date': '19350728', 'title': 'Evening star. [volume]', 'end_year': 1972, 'note': ['\"From April 25 through May 24, 1861 one sheet issues were published intermittently owing to scarcity of paper.\" Cf. Library of Congress, Photoduplication Service.', 'Also issued on microfilm from Microfilming Corp. of America and the Library of Congress, Photoduplication Service.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Publisher varies: Noyes, Baker & Co., <1867>; Evening Star Newspaper Co., <1868->', \"Suspended Jan. 1-6, 1971 because of a machinists' strike.\"], 'state': ['District of Columbia'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Washington, D.C.', 'start_year': 1854, 'edition_label': '', 'publisher': 'W.D. Wallach & Hope', 'language': ['English'], 'alt_title': ['Star', 'Sunday star'], 'lccn': 'sn83045462', 'country': 'District of Columbia', 'ocr_eng': 'FICTION 3% Sunday fitatf 28th 1935\\nSECTION WASHINGTON, D. C.\\nCover Design by J. F, Kernan\\n“The Sharpshooter” - by IRVIN S. COBB\\nMary Heaton Vorse —Roy Chapman Andrews— Emily Post\\n“No Clue Left”—by Gertrude Macaulay Sutton\\n* •', 'batch': 'dlc_1guston_ver01', 'title_normal': 'evening star.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045462/1935-07-28/ed-1/seq-71.json', 'place': ['District of Columbia--Washington'], 'page': ''}, {'sequence': 44, 'county': ['New York'], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83030214/1907-06-23/ed-1/seq-44/', 'subject': ['New York (N.Y.)--Newspapers.', 'New York (State)--New York County.--fast--(OCoLC)fst01234953', 'New York (State)--New York.--fast--(OCoLC)fst01204333', 'New York County (N.Y.)--Newspapers.'], 'city': ['New York'], 'date': '19070623', 'title': 'New-York tribune. [volume]', 'end_year': 1924, 'note': ['Also available in digital format on the Library of Congress website.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Available on microfilm from University Microfilms International, and Recordak.', 'Evening ed.: Evening edition of the tribune, 1866.', 'Merged with: New York herald (New York, N.Y. : 1920); to form: New York herald, New York tribune.', 'Semiweekly ed.: New-York tribune (New York, N.Y. : 1866 : Semiweekly), 1866-<1899>.', 'Triweekly eds.: New-York tri-weekly tribune, <1900>-1903, and: New York tribune (New York, N.Y. : 1903), 1903-<1909>.', 'Weekly ed.: New-York tribune (New York, N.Y. : 1866 : Weekly), 1866-<1906>.'], 'state': ['New York'], 'section_label': '', 'type': 'page', 'place_of_publication': 'New York [N.Y.]', 'start_year': 1866, 'edition_label': '', 'publisher': 'New York Tribune', 'language': ['English'], 'alt_title': ['Combined New York morning newspapers', 'Combined New York Sunday newspapers', 'New-York daily tribune'], 'lccn': 'sn83030214', 'country': 'New York', 'ocr_eng': \"The Biggest Kind of a Change that ever\\nHappened to Any Magazine has\\nHappened This Month to\\nTHE\\nSCRAPS\\nBGDK\\nTHE SCRAP BOOK. FOR JULY IS ISSUED IN TWO SECTIONS— TWO\\ncomplete magazine*, each with its own cover and its own table of content*.\\nOne of these section! is an ALL-ILLUSTRATED magazine; the other is an\\nALL-FICTION magazine. Each is a mammoth magazine in itself. The one\\npresents an overwhelming array of human interest articles and illustrations;\\nthe other an enormous tonnage of fiction — 160 pages of absorbing stories.\\nTen years ago I created a new type of magazine — the ALL-FICTION\\nmagazine. Now I am creating another distinct type — the ALL-ILLUS\\nTRATED magazine. This is the age of specialization. The conventional\\nmagazine, with its smattering of illustrations and its smattering of fiction\\nand its smattering of special articles, doesn't contain enough of any one\\nthing to make it satisfying. The ALL-FICTION magazine and the ALL\\nILLUSTRATED magazine, joined together as a unit, make something really\\nbig and forceful and convincing.\\nThe Only Way to Know a Thing is to Try It\\nThe TW< >-SECTION magazine idea is brand new to the world. It is a t qmte\\nnew with me, however, as I have given it. at odd times, four or five rears\\nof thought. It first came into my mind in response to a desire to couple, in\\nsome way, the strength of the all fiction magazine with the illustrated features\\nof the conventional magazine. It has been a difficult problem to work er.t.\\nNow that the idea is perfected, I wish to see what there is m it. 11 looks to\\nme to ! c very good, but the only way to know a thing is to try it.\\nTwo Magazines for Quarter Easy Money\\nThe price of this two-part magazine is twenty-jive cents, which is equal to twelve ard\\none-half cents a magazine. A/03/ magazines which were telling at ten cents have Yen\\nadvanced to fifteen cents. THE SCRAP BOOK in koo parts means two magazines\\nfor twenty-five cents against thirty cents for two fifteen cent magazines.\\nMow Ready on all News-stands\\nFRANK A. MUNSEY, New Yorh.\", 'batch': 'dlc_greece_ver01', 'title_normal': 'new-york tribune.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83030214/1907-06-23/ed-1/seq-44.json', 'place': ['New York--New York--New York'], 'page': ''}, {'sequence': 26, 'county': ['Hartford'], 'edition': None, 'frequency': 'Daily (except Sun.)', 'id': '/lccn/sn82014519/1927-04-22/ed-1/seq-26/', 'subject': ['Connecticut--Hartford County.--fast--(OCoLC)fst01211874', 'Connecticut--New Britain.--fast--(OCoLC)fst01202983', 'Hartford County (Conn.)--Newspapers.', 'New Britain (Conn.)--Newspapers.'], 'city': ['New Britain'], 'date': '19270422', 'title': 'New Britain herald. [volume]', 'end_year': 1976, 'note': ['\"Independent.\"', 'Also published by the Herald Pub. Co.: Bristol herald (Bristol, Conn.).', 'Archived issues are available in digital format from the Library of Congress Chronicling America online collection.', 'Available on microfilm from New England Micrographics, Marlboro, Mass; Connecticut State Library, Hartford, CT.'], 'state': ['Connecticut'], 'section_label': 'Second Section', 'type': 'page', 'place_of_publication': 'New Britain, Conn.', 'start_year': 1890, 'edition_label': '', 'publisher': 'Herald Pub. Co.', 'language': ['English'], 'alt_title': ['New Britain daily herald'], 'lccn': 'sn82014519', 'country': 'Connecticut ', 'ocr_eng': '6\\nNEW BRITAIN DAILY HERALD, FRIDAY, APRIL 22, 1927.\\nim,,,!\\nJU\\nill\\n4 DEI\\nHill ifll\\nr jii. hiiiiiiii miiiiii HiiHi\\nVv Mil III\\nWHO killed Garrett Fosom? And what for? One\\nmoment this middle-aged, handsome bachelor was\\na gay and laughing figure, one of a great throng of holi\\nday revelers bathing in the glorious surf of Ocean Town.\\nOne moment he was exchanging pleasantries with his\\nfriends; the next he was a stricken man, limp and life\\nless beneath the waves. Life guards carried him out of\\nthe water. They laid him on the beach, while the\\ncurious gathered and stared in awe.\\nDrowning? No. Stroke? No. Death had come as\\nthe result of a powerful knife thrust beneath the water;\\na thrust sure and deadly, but from what source no one\\nknew. Detectives, Garrett Folsom\\'s friends, even those\\nwho had stood next to him when the murder was com\\nmitted, were truly\\nALL\\nAT\\nAnd so Carolyn Wells, truly titled the \"mistress of mystery\" because of her mastery of the detective story, has\\naptly named this latest work of hers \"All at Sea.\" You have never read a story like it, never encountered\\na murder plot so baffling and strange.\\nThis new story by ihe famous Carolyn\\nWells is the first serial she has written di\\nrectly for newspaper publication. Don t\\nmiss it. It starts in The Herald Friday,\\nApril 29.\\nIt is just one more reason for your reading\\nyour fiction in The Herald. The Herald\\nhas exclusive rights in New Britain to NEA\\nService and NEA Service fiction. That\\nmeans it is the only paper here that prints\\noriginal fiction stories by such authors as\\nAnne Austin, Carolyn Wells, Virginia Swain\\nand Ernest Lvnn.\\nThe wealthy Garrett Folsom murdered. No clue except the knife, the\\ndeadly \"pichag.\" Finger .prints washed away by the salt water; foot\\nprints lost irrevocably in the shifting sands. Who did it, and why?\\nWas money the motive? Was revenge? Was jealousy?\\nIf you are a Carolyn Wells \"fan,\" be prepared for a thousand thrills in\\nthe latest story of hers. If you\\'ve never read her work, \"all at Sea\"\\nwill explain her popularity as a writer of mystery fiction.\\nRemember, \"All at Sea\" is written directly for newspaper publication.\\nIt is not a reprint from a book. It is NEA Service fiction, which means\\noriginal fiction.\\nill', 'batch': 'ct_genesis_ver01', 'title_normal': 'new britain herald.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn82014519/1927-04-22/ed-1/seq-26.json', 'place': ['Connecticut--Hartford--New Britain'], 'page': '26'}, {'sequence': 12, 'county': ['Hartford'], 'edition': None, 'frequency': 'Daily (except Sun.)', 'id': '/lccn/sn82014519/1927-04-25/ed-1/seq-12/', 'subject': ['Connecticut--Hartford County.--fast--(OCoLC)fst01211874', 'Connecticut--New Britain.--fast--(OCoLC)fst01202983', 'Hartford County (Conn.)--Newspapers.', 'New Britain (Conn.)--Newspapers.'], 'city': ['New Britain'], 'date': '19270425', 'title': 'New Britain herald. [volume]', 'end_year': 1976, 'note': ['\"Independent.\"', 'Also published by the Herald Pub. Co.: Bristol herald (Bristol, Conn.).', 'Archived issues are available in digital format from the Library of Congress Chronicling America online collection.', 'Available on microfilm from New England Micrographics, Marlboro, Mass; Connecticut State Library, Hartford, CT.'], 'state': ['Connecticut'], 'section_label': '', 'type': 'page', 'place_of_publication': 'New Britain, Conn.', 'start_year': 1890, 'edition_label': '', 'publisher': 'Herald Pub. Co.', 'language': ['English'], 'alt_title': ['New Britain daily herald'], 'lccn': 'sn82014519', 'country': 'Connecticut ', 'ocr_eng': 'u.\\nNEW BRITAIN DAILY HERALD, FRIDAY, APRIE 22, 1927.\\nM\\nLnJ\\n4\\ni D\\nnun\\nin\\n\\'IYHUI\\nw\\n1\\nIf ilk llllllllll Ifl\\'llllt IIIIUl\\nf m 111 nil ininmL\\niWi III LP\\nWHO killed Garrett FoW And what for? One\\nmoment this middle-aged, handsome bachelor was\\na gay and laughing figure, one of a great throng of holi\\nday revelers bathing in the glorious surf of Ocean Town.\\nOne moment he was exchanging pleasantries with his\\nfriends; the next he was a stricken man, limp and life\\nless beneath the waves. Life guards carried him out of\\nthe water. They laid him on the beach, while the\\ncurious gathered and stared in awe.\\nDrowning? No. Stroke? No. Death had come as\\nthe result of a powerful knife thrust beneath the water;\\na thrust sure and deadly, but from what source no one\\nknew. Detectives, Garrett Folsom\\'s friends, even those\\nwho had stood next to him when the murder was com\\nmitted, were truly\\nALL\\nAT\\nSEA\\nAnd so Carolyn Wells, truly titled the \"mistress of mystery\\' because of her mastery of the detective story, has\\naptly named this latest work of hers \"All at Sea.\" You have never read a story like it, never encountered\\na murder plot so baffling and strange.\\n1 his new story by the famous Carolyn\\nWells is the first serial she has written di\\nrectly for newspaper publication. Don\\'t\\nmiss it. It starts in The Herald Friday,\\nApril 29.\\nIt is just one more reason for your reading\\nyour fiction in The Herald. The Herald\\nhas exclusive rights in New Britain to NEA\\nService and NEA Service fiction. That\\nmeans it is the only paper here that prints\\noriginal fiction stories by such authors as\\nAnne Austin, Carolyn Wells, Virginia Swain\\nand Ernest Lynn.\\nThe wealthy Garrett Folsom murdered. No clue except the knife, the\\ndeadly \"pichag.\" Finger prints washed away by the salt water; foot\\nprints lost irrevocably in the shifting sands. Who did it, and why?\\nWas money the motive? Was revenge? Was jealousy?\\nIf you are a Carolyn Wells \"fan,\" be prepared for a thousand thrills in\\nthe latest story of hers. If you\\'ve never read her work, \"all, at Sea\\'\\nwill explain her popularity as a writer of mystery fiction.\\nRemember; \"All at Sea\" is written directly for newspaper publication.\\nIt is not a reprint from a book. It is NEA Service fiction, which means\\noriginal fiction.', 'batch': 'ct_genesis_ver01', 'title_normal': 'new britain herald.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn82014519/1927-04-25/ed-1/seq-12.json', 'place': ['Connecticut--Hartford--New Britain'], 'page': ''}, {'sequence': 15, 'county': ['Philadelphia'], 'edition': None, 'frequency': 'Daily (except Sun.)', 'id': '/lccn/sn83045211/1920-07-27/ed-1/seq-15/', 'subject': ['Pennsylvania--Philadelphia.--fast--(OCoLC)fst01204170', 'Philadelphia (Pa.)--Newspapers.'], 'city': ['Philadelphia'], 'date': '19200727', 'title': 'Evening public ledger. [volume]', 'end_year': 1942, 'note': ['Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Published as: Evening public ledger and the evening telegraph, July 1-Dec. 31, 1918.'], 'state': ['Pennsylvania'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Philadelphia [Pa.]', 'start_year': 1914, 'edition_label': 'NIGHT EXTRA', 'publisher': 'Public Ledger Co.', 'language': ['English'], 'alt_title': ['Evening public ledger and the evening telegraph'], 'lccn': 'sn83045211', 'country': 'Pennsylvania', 'ocr_eng': '1. .KV,Tt- f\\n. f \\' \\' ,ttj l \" \\'\\nf .\" , ,, H J\\n1 A ft? \\' .\\n\\'\\nfi\\njr. . t V \" t .\\n,,-\\'\" -\\n- :-iW\\nft \\' -\\n? v & t\\n- \\' ,i . \\' ; . \"c\\n1 rf in A \\'\"\\' \\'f\\nW.\\n; j , . v\\n-,\\' r\\n\\' f\\n,-V- V ; lV,.,.--\\nt: ... \\' .\\'i rpjri,:.\\n-r ;, h, r\\n0\\n7-pJ\\n. v\\nt !\\n\"\\' \\'\\',. .\" a , :.- . \\'. - ,\\n\\'. r .,.\\'\\' ,\\nt ,V ) IV\\n-\\n\\'4\\nEVHNItfGF PTJBIIO .HBDIDP PHILADBM\\'HIA, TUESDAY\", JUjjX 2f, J-u\\n, ... -,....,... .... , t i . i I \\'\\nRemember\\nJ S A mm \\' fl\\nJu v f jff mmW m MM ffi fl\\nThe ZfesJ Serial Novels of the Year\\nThe Yellow Horde . . ByHalEvarts\\nPeriwinkle House By Opie Read\\nA Daughter of Discontent\\nBy Clarence Budington Kelland\\nMr. Billings Spends His Dime . By Dana Burnet\\nThe Best Short Stories of the Month\\nDutiful Dorothy\\nThrough Hell for Him\\nMatthew Beman\\nBeyond the Desert\\nOn Paradise Peaks\\nStriped Satin\\nMaking It Human\\nNothhV Doin\\'\\nThe Night Riders\\nBy Meredith Nicholson\\nj By Wallace Irwin\\nBy William MacHarg\\nBy Alfred Noyes\\nBy Charles Collins\\nByJ.F.Natteford\\nBy Barker Shelton\\nBy Suzanne Buck\\nBy W. A, Fraser-\\n-And\\nBruce Barton\\'s Common-Sense Editorial\\ntfjQSCTOT\\'\"\\'\"\\nMasters of Fiction!\\nAsk any man or woman you chance to meet, to name, offhand, a\\nfew of the world\\'s greatest writers Invariably this challenge will\\nbring names of great writers of FICTION\\nThis should drive home to every alert and open mind the fact that\\nFiction is the form of most universal appeal in interpreting Life\\nEvery human being sees life as a drama The big, vital steps of life\\nare based on Feeling Feeling perhaps tempered and controlled by\\nReason but Feeling just the same!\\nLiterature without the play of these forces and having no power to\\nmake the reader feel, at least in a measure, as the men and women\\nfelt who left their impress upon their day, is not the kind of Litera\\nture that lingers in the human heart\\nThis is why the Masters of Fiction have enshrined themselves so\\nsecurely in the affections of readers that they are first on the tongue\\nwhen names of Great Writers are demanded\\nNo period in the world\\'s history ever offered the opportunity to the\\nartist in Fiction that confronts the story-writers of today And in\\nthis field of literary art there are a score of competent craftsmen\\nwhere there was one a half-century ago.\\nThis is one reason why THE RED BOOK MAGAZINE has become one\\nof the most powerful educational forces in America; it realizes that\\nFiction is the Master Art in the interpretation-of Life It publishes\\nonly Fiction, and the best obtainable Fiction which portrays the\\nfeelings that are shaping the destiny of Today and Tomorrow\\nTHE RED BOO\\nv\\n:j.\\n\\'\\'- \\' sklk... . H .\"\".\\'... \" \"\"\\'\" \\' \\' \"11 I\\n\\' m!v . TOlliamThackeray Nathaniel Hawthorne Washington IrviDg J\\nMa0azine KJH TKe Writers\\ni r . - w , m\" V. \\'mmsmm\\nRemade : t SW X O U\\nI is They are the\\nI Charles Didkens\\nI r \\'\\nI R Iff I\\n! \\' I\\nI\\'M\\n\\' .11\\n1 II aaDDoaaaaapBjaiMoiam feelings that are shaping the destiny of Today and Tomorrow j j\\n, - - AMim Jt . . II fl JI\\nMHHMi RflHKi HHBi mw9Mk GLW siui Ih HHHHfl 8HHHM 9H&. viHi uQ II a\\nML Ilk, A. T lLl MMmmSLWM M ,y K w m t\\n3\\nj\\n\"\"\"\" \\' \"\" \" rl \" I\\np\\nOn sale at all newrs stands i\\nPrice 25 cents . , j\\nrj\\n\" 5l\\n-v\\nl', 'batch': 'pst_holuba_ver02', 'title_normal': 'evening public ledger.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045211/1920-07-27/ed-1/seq-15.json', 'place': ['Pennsylvania--Philadelphia--Philadelphia'], 'page': ''}, {'sequence': 78, 'county': [None], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83045462/1943-04-11/ed-1/seq-78/', 'subject': ['Washington (D.C.)--fast--(OCoLC)fst01204505', 'Washington (D.C.)--Newspapers.'], 'city': ['Washington'], 'date': '19430411', 'title': 'Evening star. [volume]', 'end_year': 1972, 'note': ['\"From April 25 through May 24, 1861 one sheet issues were published intermittently owing to scarcity of paper.\" Cf. Library of Congress, Photoduplication Service.', 'Also issued on microfilm from Microfilming Corp. of America and the Library of Congress, Photoduplication Service.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Publisher varies: Noyes, Baker & Co., <1867>; Evening Star Newspaper Co., <1868->', \"Suspended Jan. 1-6, 1971 because of a machinists' strike.\"], 'state': ['District of Columbia'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Washington, D.C.', 'start_year': 1854, 'edition_label': '', 'publisher': 'W.D. Wallach & Hope', 'language': ['English'], 'alt_title': ['Star', 'Sunday star'], 'lccn': 'sn83045462', 'country': 'District of Columbia', 'ocr_eng': \"This Week\\n/\\n— MAGAZINE '\\nSECTION\\nPje J&untUty ptaf\\nWASHINGTON. D. C.\\nAPRIL 11. 1843\\n★\\nSQOAWKERS? IF YOU KNOW\\nANY, READ THEM THIS ...\\nPage 2... Editorial\\nTHE WHITE PIGEON: THE\\nSTORY OF A YOUNG HERO\\nPage 4... Fiction\\nNIGHT FIGHTERS... HOW\\nTHEY DOWN NAZI PLANES\\nPage 5... Article\\nPERSONAL NOTE: WATCH\\nLILY SELL WAR BONDS!\\nPage 8... Fiction\\nTHOSE GREMLINS...HERE\\nARE WORDS Or WARNING!\\nPage 12... Article\\nFOOD... BEAUTY... MOVIE\\nSPOTLIGHT... CARTOONS\\nIHIFBUILDBR, 1143\\nShe is Miss Mabel Tourney,\\nof Delta, Colorado. While\\nher brother, Corp. Leonard\\nTourney, serves Uncle Sam\\nin the Sixth Armored Divi«\\nsion, she dou her own share\\nby working at the plant of\\nthe California Shipbuilding\\nCorporation, Wilmington, Cal.\", 'batch': 'dlc_1xul_ver01', 'title_normal': 'evening star.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045462/1943-04-11/ed-1/seq-78.json', 'place': ['District of Columbia--Washington'], 'page': ''}, {'sequence': 9, 'county': ['Ohio'], 'edition': None, 'frequency': 'Daily (except Sunday)', 'id': '/lccn/sn86092536/1920-01-03/ed-1/seq-9/', 'subject': ['Ohio County (W. Va.)--Newspapers.', 'West Virginia--Ohio County.--fast--(OCoLC)fst01224107', 'West Virginia--Wheeling.--fast--(OCoLC)fst01213675', 'Wheeling (W. Va.)--Newspapers.'], 'city': ['Wheeling'], 'date': '19200103', 'title': 'The Wheeling intelligencer. [volume]', 'end_year': 1961, 'note': ['Archived issues are available in digital format from the Library of Congress Chronicling America online collection.', 'Available on microfilm from Bell & Howell Information and Learning and Microfilming Corporation of Pennsylvania.'], 'state': ['West Virginia'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Wheeling, W. Va.', 'start_year': 1903, 'edition_label': '', 'publisher': 'Intelligencer Pub. Co.', 'language': ['English'], 'alt_title': ['Intelligencer'], 'lccn': 'sn86092536', 'country': 'West Virginia', 'ocr_eng': 'OW often do you hear\\npeople say ? \" How\\nshall we kill the\\nevening?\"\\nThink of killing time, man\\'s\\nmost precious asset!\\nWhy not use an evening ?\\nthis evening if you will.\\nIf you like fiction, read the\\nkind that will stimulate your\\nimagination ? that will inspire\\nand entertain you.\\nThat means fiction by really\\ngreat, really important writers.\\nSuch fiction is more than mere\\nentertainment ? it is literature\\n? the best and finest literature\\nof our day.\\nIt isn\\'t what we say about\\nthese writers that makes them\\ngreat. ? It\\'s what you tinelli\\ngent,c progressive magazine\\nreaders think about themthat\\nestablishes their reputation.\\nThat\\'s why the American\\npublic pays more for the privi\\nlege of reading Cosmopolitan\\nthan it pays for the single\\nedition of any other magazine.\\nFor it is the policy of\\nCosmopolitan to give the\\nmagazine readers of America\\nthe best magazine that it is\\npossible to produce .\\nThe best editorially , the\\nbest mechanically ? every\\nmonth in the year, and year\\nafter year.\\n?J* \"v\\nWhen you get the December\\nnumber of Cosmopolitan you\\nwill have the satisfaction of\\nknowing that you have the\\nbest magazine that money can\\nbuy .J\\nMore ? when you read it you\\nknow that you are doing\\nsomething more profitable\\nthan \"killing time\" ? you are\\nusing it to the best possible\\nadvantage that the reading of\\nfiction gives.\\nIt was Lord Francis Bacon\\nwho said, \" reading serves for\\ndelight , for ornament , for\\nability. The crafty condemn it ,\\nthe simple admire it, the wise\\nuse it\\nAnd the better part of wis\\ndom in reading is to read the\\nbest literature of the day.\\nThat means Cosmopolitan .\\n5*>\\ntH^oa\\nUof\\n\\'S5 /J&fr\\nAt Alt\\nI outlet, no*\\nfrom f kc j an inlet,\\nfact\\'side / 1^\\nbwfc From, / C-AJpfom^o&aitii\\ntk heart - 1', 'batch': 'wvu_jim_ver01', 'title_normal': 'wheeling intelligencer.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn86092536/1920-01-03/ed-1/seq-9.json', 'place': ['West Virginia--Ohio--Wheeling'], 'page': '9'}, {'sequence': 11, 'county': ['Shelby'], 'edition': None, 'frequency': 'Daily (except Sun.)', 'id': '/lccn/sn98069867/1920-01-02/ed-1/seq-11/', 'subject': ['Memphis (Tenn.)--Newspapers.', 'Shelby County (Tenn.)--Newspapers.', 'Tennessee--Memphis.--fast--(OCoLC)fst01204194', 'Tennessee--Shelby County.--fast--(OCoLC)fst01209894'], 'city': ['Memphis'], 'date': '19200102', 'title': 'The news scimitar.', 'end_year': 1926, 'note': ['\"Memphis\" appears in masthead ornament Apr. 1, 1921-Nov. 15, 1926.', 'Archived issues are available in digital format from the Library of Congress Chronicling America online collection.', 'Merged with: Memphis press, to form: Memphis press-scimitar.'], 'state': ['Tennessee'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Memphis, Tenn.', 'start_year': 1907, 'edition_label': '4th EDITION', 'publisher': 'Gilbert D. Raine', 'language': ['English'], 'alt_title': ['Memphis news scimitar', 'Sunday illustrated news scimitar'], 'lccn': 'sn98069867', 'country': 'Tennessee', 'ocr_eng': 'mOAY.VANUAHY 2, 1120.\\nDecember,\\n6\\ns.\\nj\\n7)1\\n7i\\nAmerica\\'s QrertestJifaqdzine\\ni\\n4-r\\nfZheimfazitte\\nTHE NEWS SCIMITAR.\\nPAGE ELEVEN\\n! I\\n;\\nMi,\\nmm\\nmmm\\ntime\\nuse of it\\nOW often do you hear\\npeople say \"How\\nshall we kill the\\nevening? \"\\nThink of killing time, man\\'s\\nmost precious asset!\\nWhy not use ail evening this\\nevening if you will.\\nIf you like fiction, read the kind\\nthat will stimulate your imagin\\nationthat will inspire and enter\\ntain you.\\nThat means fiction by really\\ngreat, really important writers.\\nSuch fiction is more than mere\\nentertainment -at is literature\\nthe best and finest literature of\\nour day. \\'\\nIt isn\\'t what we say about these\\nwriters that makes them great.\\nIt\\'s what you intelligent, progress\\nive magazine readers think about\\nthem that establishes their repu\\ntation. That\\'s why the American public\\npays more for the privilege of read\\ning Cosmopolitan than it pays for\\nthe single edition of any other\\nmagazine.\\nFor it is the policy of Cosmopoli\\ntan to give the magazine readers\\nof America the best magazine that\\nit is possible to produce.\\nThe best editorially, the best\\nmechanicallyevery month in the\\nyear, and year after year.\\nWhen, you get the December\\nnumber of Cosmopolitan you will\\nhave the satisfaction of knowing\\nthat you have the best magazine that\\nmoney can buy.\\nMore when you read it you\\nknow that you are\" doing something\\nmore profitable than \"killing time\"\\nyou are using it to the best pos\\nsible advantage that the reading\\nof fiction gives.\\nIt was Lord Francis Bacon who\\nsaid, reading serves for delight, for\\nornament, for ability. The crafty\\ncondemn it, the simple admire it, the\\nwise use it.\"\\nAnd the better part of wisdom\\nin reading is to read the best lit\\nerature of the day.\\nThat means Cosmopolitan.\\nFor Sale By\\nDrugstores \\'\\nMagazine Stands m\\nHotel Cigar Stands f\\nGrand Central Station\\n7\\nDistributed By\\nREESE MAGAZINE AGENCY\\n8 North Front St. i\\nMemphis, Tenn.\\nU4.\\'\\nnot\\n\"America\\'s Greatest Magazine', 'batch': 'tu_carla_ver01', 'title_normal': 'news scimitar.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn98069867/1920-01-02/ed-1/seq-11.json', 'place': ['Tennessee--Shelby--Memphis'], 'page': 'PAGE ELEVEN'}, {'sequence': 44, 'county': ['New York'], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83030214/1919-06-15/ed-1/seq-44/', 'subject': ['New York (N.Y.)--Newspapers.', 'New York (State)--New York County.--fast--(OCoLC)fst01234953', 'New York (State)--New York.--fast--(OCoLC)fst01204333', 'New York County (N.Y.)--Newspapers.'], 'city': ['New York'], 'date': '19190615', 'title': 'New-York tribune. [volume]', 'end_year': 1924, 'note': ['Also available in digital format on the Library of Congress website.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Available on microfilm from University Microfilms International, and Recordak.', 'Evening ed.: Evening edition of the tribune, 1866.', 'Merged with: New York herald (New York, N.Y. : 1920); to form: New York herald, New York tribune.', 'Semiweekly ed.: New-York tribune (New York, N.Y. : 1866 : Semiweekly), 1866-<1899>.', 'Triweekly eds.: New-York tri-weekly tribune, <1900>-1903, and: New York tribune (New York, N.Y. : 1903), 1903-<1909>.', 'Weekly ed.: New-York tribune (New York, N.Y. : 1866 : Weekly), 1866-<1906>.'], 'state': ['New York'], 'section_label': '', 'type': 'page', 'place_of_publication': 'New York [N.Y.]', 'start_year': 1866, 'edition_label': '', 'publisher': 'New York Tribune', 'language': ['English'], 'alt_title': ['Combined New York morning newspapers', 'Combined New York Sunday newspapers', 'New-York daily tribune'], 'lccn': 'sn83030214', 'country': 'New York', 'ocr_eng': '\"Little Nell and Her Grandfather\"\\n(The Old Curiosity Shop, by Charles Dickens)\\nFrom a \"Veriplica\" Painting After Arthur I). McCormick\\nYour memory of Di?kens\\'.s \"Old Curiosity Shop\" responds\\ninstantly to the truth and charm of the artist\\'s conception\\nof two of the best loved characters in fiction the winsome\\nchild, who mothered old Trent through his weakness and\\nwandering, and the pathetic old deceiver, whose sole ambi?\\ntion was to gamble and win great riches for Little Nell.', 'batch': 'dlc_carril_ver01', 'title_normal': 'new-york tribune.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83030214/1919-06-15/ed-1/seq-44.json', 'place': ['New York--New York--New York'], 'page': '8'}, {'sequence': 140, 'county': [None], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83045462/1951-11-18/ed-1/seq-140/', 'subject': ['Washington (D.C.)--fast--(OCoLC)fst01204505', 'Washington (D.C.)--Newspapers.'], 'city': ['Washington'], 'date': '19511118', 'title': 'Evening star. [volume]', 'end_year': 1972, 'note': ['\"From April 25 through May 24, 1861 one sheet issues were published intermittently owing to scarcity of paper.\" Cf. Library of Congress, Photoduplication Service.', 'Also issued on microfilm from Microfilming Corp. of America and the Library of Congress, Photoduplication Service.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Publisher varies: Noyes, Baker & Co., <1867>; Evening Star Newspaper Co., <1868->', \"Suspended Jan. 1-6, 1971 because of a machinists' strike.\"], 'state': ['District of Columbia'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Washington, D.C.', 'start_year': 1854, 'edition_label': '', 'publisher': 'W.D. Wallach & Hope', 'language': ['English'], 'alt_title': ['Star', 'Sunday star'], 'lccn': 'sn83045462', 'country': 'District of Columbia', 'ocr_eng': 'SPECTACLE\\nNEVER BEFORE FILMED!\\nGIANT PLANET COLLIDES WITH EARTH!\\n•\\nENORMOUS EARTHQUAKES\\nSWALLOW WHOLE CONTINENTS!\\n•\\nTIDAL WAVES FLOOD ENTIRE COUNTRIES!\\nSPACE SHIP LEAVES EARTH!\\nParamount presents\\nProduced By GEORGE PAL Directed By RUDOLPH MATE Screenplay By SYDNEY BOEHM * Most Amazing Story\\nThat Science Or Fiction Ever Imagined... Based on The Sensational Book By EDWIN BALMER and PHILIP WYLIE', 'batch': 'dlc_2nevelson_ver01', 'title_normal': 'evening star.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045462/1951-11-18/ed-1/seq-140.json', 'place': ['District of Columbia--Washington'], 'page': '17'}, {'sequence': 80, 'county': [None], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83045462/1942-03-15/ed-1/seq-80/', 'subject': ['Washington (D.C.)--fast--(OCoLC)fst01204505', 'Washington (D.C.)--Newspapers.'], 'city': ['Washington'], 'date': '19420315', 'title': 'Evening star. [volume]', 'end_year': 1972, 'note': ['\"From April 25 through May 24, 1861 one sheet issues were published intermittently owing to scarcity of paper.\" Cf. Library of Congress, Photoduplication Service.', 'Also issued on microfilm from Microfilming Corp. of America and the Library of Congress, Photoduplication Service.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Publisher varies: Noyes, Baker & Co., <1867>; Evening Star Newspaper Co., <1868->', \"Suspended Jan. 1-6, 1971 because of a machinists' strike.\"], 'state': ['District of Columbia'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Washington, D.C.', 'start_year': 1854, 'edition_label': '', 'publisher': 'W.D. Wallach & Hope', 'language': ['English'], 'alt_title': ['Star', 'Sunday star'], 'lccn': 'sn83045462', 'country': 'District of Columbia', 'ocr_eng': 'wiclay;\\nfUNGTON, D.\\nI I\\n: V I\\nn\\nII I\\n■ I\\nREVENGE IN NORWAY\\nA; ,- -t V . ’• vVj\\ndust SDMI story or\\n• soldier is disguise |||S;\\nALSO...\\nMore Short Fiction—\\nDramatized Articles—\\nFeed—Beauty—Cartoons\\n—Pictures\\nWAR changes stars, too. Typical Is Rosalind Russell. She’s on Hollywood’s Victory\\nCommittee, belongs to Emergency Ambulance Corps, entertains at the comps', 'batch': 'dlc_1udaltsova_ver02', 'title_normal': 'evening star.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045462/1942-03-15/ed-1/seq-80.json', 'place': ['District of Columbia--Washington'], 'page': ''}, {'sequence': 22, 'county': ['Douglas'], 'edition': '[Morning ed.].', 'frequency': 'Daily', 'id': '/lccn/sn99021999/1916-09-17/ed-1/seq-22/', 'subject': ['Nebraska--Omaha.--fast--(OCoLC)fst01204995', 'Omaha (Neb.)--Newspapers.'], 'city': ['Omaha'], 'date': '19160917', 'title': 'Omaha daily bee.', 'end_year': 1922, 'note': ['Also issued on microfilm from Nebraska State Historical Society and UMI.', 'Description based on: Vol. 2, no. 163 (Dec. 31, 1872).', 'Evening ed.: Omaha daily bee, <1872>-1892; Omaha evening bee, 1892-1927.', 'Issues lack numbering, 1893-1906.', 'Weekly ed.: Weekly bee (Omaha, Neb.), <1872>-1900.'], 'state': ['Nebraska'], 'section_label': 'PART IV', 'type': 'page', 'place_of_publication': 'Omaha [Neb.]', 'start_year': 1870, 'edition_label': '', 'publisher': 'Edward Rosewater', 'language': ['English'], 'alt_title': ['Omaha Sunday bee'], 'lccn': 'sn99021999', 'country': 'Nebraska', 'ocr_eng': '\\' ! (SUZANMEPOYOUJEKMOVA .OH, HAPPY. Look AT\"U- CAU I 1\\nTfe Happy HliamHoBepiiooB\\nJgli His Advcntures Provc That Truth Is\\ny\\'\\'SJ\\' yfySzf - - \"\\' Stranger, Than Fiction!\\nout now?! must! SLJjy . j Hflppr HoouwAgr v1 w) THtrterl\\nY&f 1 Yple u IIP1P A Will invite) ,TntKlt \\' r ) B\\n. . S WwM\\' teJKIwEi permit S WWw&r\\' y flak\\n\\' y', 'batch': 'nbu_azureaster_ver01', 'title_normal': 'omaha daily bee.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn99021999/1916-09-17/ed-1/seq-22.json', 'place': ['Nebraska--Douglas--Omaha'], 'page': ''}, {'sequence': 83, 'county': [None], 'edition': None, 'frequency': 'Daily', 'id': '/lccn/sn83045462/1947-04-27/ed-1/seq-83/', 'subject': ['Washington (D.C.)--fast--(OCoLC)fst01204505', 'Washington (D.C.)--Newspapers.'], 'city': ['Washington'], 'date': '19470427', 'title': 'Evening star. [volume]', 'end_year': 1972, 'note': ['\"From April 25 through May 24, 1861 one sheet issues were published intermittently owing to scarcity of paper.\" Cf. Library of Congress, Photoduplication Service.', 'Also issued on microfilm from Microfilming Corp. of America and the Library of Congress, Photoduplication Service.', 'Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Publisher varies: Noyes, Baker & Co., <1867>; Evening Star Newspaper Co., <1868->', \"Suspended Jan. 1-6, 1971 because of a machinists' strike.\"], 'state': ['District of Columbia'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Washington, D.C.', 'start_year': 1854, 'edition_label': '', 'publisher': 'W.D. Wallach & Hope', 'language': ['English'], 'alt_title': ['Star', 'Sunday star'], 'lccn': 'sn83045462', 'country': 'District of Columbia', 'ocr_eng': 'SCIENCE OH A SPREE\\nby Leslie Lieber\\n— tNCE EXPERT John W. Campbell \"invents\" fantastic gadgets in his home lab\\nDon\\'t laugh at screwball science fiction. It\\'s\\nfull of space ships and robots, but the gadgets\\nare often bull\\'s-eye predictions of things to come\\nTHE first atom-bomb explo\\nsion in history did not\\ntake place July 16, 1945, on a\\nNew Mexico desert. Actually,\\nΑ-Bomb No. 1 exploded a\\ngood 15 years before that — on page 56 of\\n\"Astounding Science Fiction Magazine.\"\\nThe writer who described that holocaust\\nnot only used Uranium-235 in his story, but\\naccurately foretold the strength of the explo\\nsion and its deadly after-effects.\\nJust a fluke prediction? Perhaps. But what\\nabout science fiction\\'s next stroke of clair\\nvoyance? Just a short time after Pearl Harbor,\\nanother pulp-magazine yarn described the\\ndropping of an atomic empire-buster on\\nJapan. That\\'s the way science fiction end\\ned the war, ami that\\'» the way history\\nwound it up three years later.\\nNow, if those two were the only successful\\n\"guesses,\" we could just chalk the whole thing\\nup to some author\\'s pipe-dreaming type\\nwriter, and let the whole matter drop.\\nhistory. By far the great majority of them are\\nmen (the outer reaches of space are pioneer\\nregions unfit for feminine habitation).\\nMany readers are distinguished citizens of\\nthe worldof non-fiction science. \"Astounding,\"\\nfor example, claims among its fans several\\nphysics professors, including Dr. J. R. Oppen\\nheimer and fellow atomic scientists; R. S.\\nRichardson, solar specialist of Mt. Wilson\\nObservatory; John R. Pierce, inventor of the\\ntraveling wave amplifier; Willy Ley, author\\nof \"Rockets.\"\\nBig-nun· By-lincc\\nWhen Dr. Herman J. Muller, a recent Nobel\\nPrize winner, left for Stockholm to receive\\nhis award, he was photographed with his face\\nburied in a copy of \"Astounding.\"\\nAmong the men of academic achievement\\nwhose by-lines have often appeared on SF\\npieces are: J. B. S. Haldane; Julian Huxley;\\nRobert Henlein, plastic-research engineer,\\nwhose story \"Solution Unsatisfactory,\" accu\\nrately predicted the international dilemma\\nresulting from the use of atomic weapons, and\\nof course, the old master, H. G. Wells, fiction\\'s\\nmost prolific inventor of fabulous gadgets.\\nSF readers are blasé, almost incapable of\\nsurprise and amazement. To them \"Astoynd\\ning\\'s\" sundering of the atom was no more\\nexciting than splitting an infinitive. They\\'ve\\nseen everything, been everyplace — even be\\nyond the horizon and back.\\nFor instance, who do you think sketched\\nthe first workable blueprints for television?\\nIt\\'s Not Coincidence\\nΓ HE trouble with that complacent theory is\\nthat \"Astounding\" — and sister newsstand\\nthrillers like \"Startling,\" \"Thrilling Wonder\\nStories,\" \"Planet\" and \"Amazing\" — have\\nmade Ux> many bull\\'s-eye predictions to be\\ndismissed as \"pure coincidence.\"\\nToday, there are approximately 250,000\\ndevotees of science fiction in the United\\nStates. They probably constitute the most\\nscientifically-hep reading public in magazine\\nappeared in 1941 as something new. But see panel on next page', 'batch': 'dlc_2delaunay_ver01', 'title_normal': 'evening star.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83045462/1947-04-27/ed-1/seq-83.json', 'place': ['District of Columbia--Washington'], 'page': '4'}]}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we \"normalize\" the dataframe key `items`, we turn it into a dataframe, and when we call the dataframe, we get the contents of this item in the dictionary in a dataframe format. Keys are at the top of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = pd.DataFrame.from_dict(pd.io.json.json_normalize(data['items']))\n",
    "\n",
    "#RG -- note that in order for this code to run, we have to invoke the pd.io.json object which houses the normalize function.\n",
    "#So I've changed the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt_title</th>\n",
       "      <th>batch</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>county</th>\n",
       "      <th>date</th>\n",
       "      <th>edition</th>\n",
       "      <th>edition_label</th>\n",
       "      <th>end_year</th>\n",
       "      <th>frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>publisher</th>\n",
       "      <th>section_label</th>\n",
       "      <th>sequence</th>\n",
       "      <th>start_year</th>\n",
       "      <th>state</th>\n",
       "      <th>subject</th>\n",
       "      <th>title</th>\n",
       "      <th>title_normal</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Call, Call-chronicle-examiner, Sunday call]</td>\n",
       "      <td>curiv_quincy_ver01</td>\n",
       "      <td>[San Francisco]</td>\n",
       "      <td>California</td>\n",
       "      <td>[San Francisco]</td>\n",
       "      <td>19041218</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1913</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>Charles M. Shortridge</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1895</td>\n",
       "      <td>[California]</td>\n",
       "      <td>[California--San Francisco Bay Area.--fast--(O...</td>\n",
       "      <td>The San Francisco call. [volume]</td>\n",
       "      <td>san francisco call.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Call, Call-chronicle-examiner, Sunday call]</td>\n",
       "      <td>curiv_darwin_ver01</td>\n",
       "      <td>[San Francisco]</td>\n",
       "      <td>California</td>\n",
       "      <td>[San Francisco]</td>\n",
       "      <td>19031227</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1913</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>Charles M. Shortridge</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1895</td>\n",
       "      <td>[California]</td>\n",
       "      <td>[California--San Francisco Bay Area.--fast--(O...</td>\n",
       "      <td>The San Francisco call. [volume]</td>\n",
       "      <td>san francisco call.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Star, Sunday star]</td>\n",
       "      <td>dlc_1tatlin_ver01</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>[None]</td>\n",
       "      <td>19411123</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1972</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>W.D. Wallach &amp; Hope</td>\n",
       "      <td></td>\n",
       "      <td>84</td>\n",
       "      <td>1854</td>\n",
       "      <td>[District of Columbia]</td>\n",
       "      <td>[Washington (D.C.)--fast--(OCoLC)fst01204505, ...</td>\n",
       "      <td>Evening star. [volume]</td>\n",
       "      <td>evening star.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Star, Sunday star]</td>\n",
       "      <td>dlc_1miro_ver02</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>[None]</td>\n",
       "      <td>19381218</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1972</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>W.D. Wallach &amp; Hope</td>\n",
       "      <td></td>\n",
       "      <td>113</td>\n",
       "      <td>1854</td>\n",
       "      <td>[District of Columbia]</td>\n",
       "      <td>[Washington (D.C.)--fast--(OCoLC)fst01204505, ...</td>\n",
       "      <td>Evening star. [volume]</td>\n",
       "      <td>evening star.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Star, Sunday star]</td>\n",
       "      <td>dlc_2feininger_ver01</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>[None]</td>\n",
       "      <td>19480801</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1972</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>W.D. Wallach &amp; Hope</td>\n",
       "      <td></td>\n",
       "      <td>76</td>\n",
       "      <td>1854</td>\n",
       "      <td>[District of Columbia]</td>\n",
       "      <td>[Washington (D.C.)--fast--(OCoLC)fst01204505, ...</td>\n",
       "      <td>Evening star. [volume]</td>\n",
       "      <td>evening star.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Star, Sunday star]</td>\n",
       "      <td>dlc_2kandinsky_ver01</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>[None]</td>\n",
       "      <td>19500423</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1972</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>W.D. Wallach &amp; Hope</td>\n",
       "      <td></td>\n",
       "      <td>112</td>\n",
       "      <td>1854</td>\n",
       "      <td>[District of Columbia]</td>\n",
       "      <td>[Washington (D.C.)--fast--(OCoLC)fst01204505, ...</td>\n",
       "      <td>Evening star. [volume]</td>\n",
       "      <td>evening star.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>iune_echo_ver01</td>\n",
       "      <td>[Chicago]</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>[Cook County]</td>\n",
       "      <td>19120307</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1917</td>\n",
       "      <td>Daily (except Sunday and holidays)</td>\n",
       "      <td>...</td>\n",
       "      <td>N.D. Cochran</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1911</td>\n",
       "      <td>[Illinois]</td>\n",
       "      <td>[Chicago (Ill.)--Newspapers., Illinois--Chicag...</td>\n",
       "      <td>The day book. [volume]</td>\n",
       "      <td>day book.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Star, Sunday star]</td>\n",
       "      <td>dlc_1guston_ver01</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>[None]</td>\n",
       "      <td>19350728</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1972</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>W.D. Wallach &amp; Hope</td>\n",
       "      <td></td>\n",
       "      <td>71</td>\n",
       "      <td>1854</td>\n",
       "      <td>[District of Columbia]</td>\n",
       "      <td>[Washington (D.C.)--fast--(OCoLC)fst01204505, ...</td>\n",
       "      <td>Evening star. [volume]</td>\n",
       "      <td>evening star.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Combined New York morning newspapers, Combine...</td>\n",
       "      <td>dlc_greece_ver01</td>\n",
       "      <td>[New York]</td>\n",
       "      <td>New York</td>\n",
       "      <td>[New York]</td>\n",
       "      <td>19070623</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1924</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>New York Tribune</td>\n",
       "      <td></td>\n",
       "      <td>44</td>\n",
       "      <td>1866</td>\n",
       "      <td>[New York]</td>\n",
       "      <td>[New York (N.Y.)--Newspapers., New York (State...</td>\n",
       "      <td>New-York tribune. [volume]</td>\n",
       "      <td>new-york tribune.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[New Britain daily herald]</td>\n",
       "      <td>ct_genesis_ver01</td>\n",
       "      <td>[New Britain]</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>[Hartford]</td>\n",
       "      <td>19270422</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1976</td>\n",
       "      <td>Daily (except Sun.)</td>\n",
       "      <td>...</td>\n",
       "      <td>Herald Pub. Co.</td>\n",
       "      <td>Second Section</td>\n",
       "      <td>26</td>\n",
       "      <td>1890</td>\n",
       "      <td>[Connecticut]</td>\n",
       "      <td>[Connecticut--Hartford County.--fast--(OCoLC)f...</td>\n",
       "      <td>New Britain herald. [volume]</td>\n",
       "      <td>new britain herald.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[New Britain daily herald]</td>\n",
       "      <td>ct_genesis_ver01</td>\n",
       "      <td>[New Britain]</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>[Hartford]</td>\n",
       "      <td>19270425</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1976</td>\n",
       "      <td>Daily (except Sun.)</td>\n",
       "      <td>...</td>\n",
       "      <td>Herald Pub. Co.</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>1890</td>\n",
       "      <td>[Connecticut]</td>\n",
       "      <td>[Connecticut--Hartford County.--fast--(OCoLC)f...</td>\n",
       "      <td>New Britain herald. [volume]</td>\n",
       "      <td>new britain herald.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Evening public ledger and the evening telegraph]</td>\n",
       "      <td>pst_holuba_ver02</td>\n",
       "      <td>[Philadelphia]</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>[Philadelphia]</td>\n",
       "      <td>19200727</td>\n",
       "      <td>None</td>\n",
       "      <td>NIGHT EXTRA</td>\n",
       "      <td>1942</td>\n",
       "      <td>Daily (except Sun.)</td>\n",
       "      <td>...</td>\n",
       "      <td>Public Ledger Co.</td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>1914</td>\n",
       "      <td>[Pennsylvania]</td>\n",
       "      <td>[Pennsylvania--Philadelphia.--fast--(OCoLC)fst...</td>\n",
       "      <td>Evening public ledger. [volume]</td>\n",
       "      <td>evening public ledger.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Star, Sunday star]</td>\n",
       "      <td>dlc_1xul_ver01</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>[None]</td>\n",
       "      <td>19430411</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1972</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>W.D. Wallach &amp; Hope</td>\n",
       "      <td></td>\n",
       "      <td>78</td>\n",
       "      <td>1854</td>\n",
       "      <td>[District of Columbia]</td>\n",
       "      <td>[Washington (D.C.)--fast--(OCoLC)fst01204505, ...</td>\n",
       "      <td>Evening star. [volume]</td>\n",
       "      <td>evening star.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Intelligencer]</td>\n",
       "      <td>wvu_jim_ver01</td>\n",
       "      <td>[Wheeling]</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>[Ohio]</td>\n",
       "      <td>19200103</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1961</td>\n",
       "      <td>Daily (except Sunday)</td>\n",
       "      <td>...</td>\n",
       "      <td>Intelligencer Pub. Co.</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>1903</td>\n",
       "      <td>[West Virginia]</td>\n",
       "      <td>[Ohio County (W. Va.)--Newspapers., West Virgi...</td>\n",
       "      <td>The Wheeling intelligencer. [volume]</td>\n",
       "      <td>wheeling intelligencer.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8609...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[Memphis news scimitar, Sunday illustrated new...</td>\n",
       "      <td>tu_carla_ver01</td>\n",
       "      <td>[Memphis]</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>[Shelby]</td>\n",
       "      <td>19200102</td>\n",
       "      <td>None</td>\n",
       "      <td>4th EDITION</td>\n",
       "      <td>1926</td>\n",
       "      <td>Daily (except Sun.)</td>\n",
       "      <td>...</td>\n",
       "      <td>Gilbert D. Raine</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>1907</td>\n",
       "      <td>[Tennessee]</td>\n",
       "      <td>[Memphis (Tenn.)--Newspapers., Shelby County (...</td>\n",
       "      <td>The news scimitar.</td>\n",
       "      <td>news scimitar.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn9806...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[Combined New York morning newspapers, Combine...</td>\n",
       "      <td>dlc_carril_ver01</td>\n",
       "      <td>[New York]</td>\n",
       "      <td>New York</td>\n",
       "      <td>[New York]</td>\n",
       "      <td>19190615</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1924</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>New York Tribune</td>\n",
       "      <td></td>\n",
       "      <td>44</td>\n",
       "      <td>1866</td>\n",
       "      <td>[New York]</td>\n",
       "      <td>[New York (N.Y.)--Newspapers., New York (State...</td>\n",
       "      <td>New-York tribune. [volume]</td>\n",
       "      <td>new-york tribune.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8303...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[Star, Sunday star]</td>\n",
       "      <td>dlc_2nevelson_ver01</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>[None]</td>\n",
       "      <td>19511118</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1972</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>W.D. Wallach &amp; Hope</td>\n",
       "      <td></td>\n",
       "      <td>140</td>\n",
       "      <td>1854</td>\n",
       "      <td>[District of Columbia]</td>\n",
       "      <td>[Washington (D.C.)--fast--(OCoLC)fst01204505, ...</td>\n",
       "      <td>Evening star. [volume]</td>\n",
       "      <td>evening star.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[Star, Sunday star]</td>\n",
       "      <td>dlc_1udaltsova_ver02</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>[None]</td>\n",
       "      <td>19420315</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1972</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>W.D. Wallach &amp; Hope</td>\n",
       "      <td></td>\n",
       "      <td>80</td>\n",
       "      <td>1854</td>\n",
       "      <td>[District of Columbia]</td>\n",
       "      <td>[Washington (D.C.)--fast--(OCoLC)fst01204505, ...</td>\n",
       "      <td>Evening star. [volume]</td>\n",
       "      <td>evening star.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[Omaha Sunday bee]</td>\n",
       "      <td>nbu_azureaster_ver01</td>\n",
       "      <td>[Omaha]</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>[Douglas]</td>\n",
       "      <td>19160917</td>\n",
       "      <td>[Morning ed.].</td>\n",
       "      <td></td>\n",
       "      <td>1922</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>Edward Rosewater</td>\n",
       "      <td>PART IV</td>\n",
       "      <td>22</td>\n",
       "      <td>1870</td>\n",
       "      <td>[Nebraska]</td>\n",
       "      <td>[Nebraska--Omaha.--fast--(OCoLC)fst01204995, O...</td>\n",
       "      <td>Omaha daily bee.</td>\n",
       "      <td>omaha daily bee.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn9902...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[Star, Sunday star]</td>\n",
       "      <td>dlc_2delaunay_ver01</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>[None]</td>\n",
       "      <td>19470427</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1972</td>\n",
       "      <td>Daily</td>\n",
       "      <td>...</td>\n",
       "      <td>W.D. Wallach &amp; Hope</td>\n",
       "      <td></td>\n",
       "      <td>83</td>\n",
       "      <td>1854</td>\n",
       "      <td>[District of Columbia]</td>\n",
       "      <td>[Washington (D.C.)--fast--(OCoLC)fst01204505, ...</td>\n",
       "      <td>Evening star. [volume]</td>\n",
       "      <td>evening star.</td>\n",
       "      <td>page</td>\n",
       "      <td>https://chroniclingamerica.loc.gov/lccn/sn8304...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            alt_title                 batch  \\\n",
       "0        [Call, Call-chronicle-examiner, Sunday call]    curiv_quincy_ver01   \n",
       "1        [Call, Call-chronicle-examiner, Sunday call]    curiv_darwin_ver01   \n",
       "2                                 [Star, Sunday star]     dlc_1tatlin_ver01   \n",
       "3                                 [Star, Sunday star]       dlc_1miro_ver02   \n",
       "4                                 [Star, Sunday star]  dlc_2feininger_ver01   \n",
       "5                                 [Star, Sunday star]  dlc_2kandinsky_ver01   \n",
       "6                                                  []       iune_echo_ver01   \n",
       "7                                 [Star, Sunday star]     dlc_1guston_ver01   \n",
       "8   [Combined New York morning newspapers, Combine...      dlc_greece_ver01   \n",
       "9                          [New Britain daily herald]      ct_genesis_ver01   \n",
       "10                         [New Britain daily herald]      ct_genesis_ver01   \n",
       "11  [Evening public ledger and the evening telegraph]      pst_holuba_ver02   \n",
       "12                                [Star, Sunday star]        dlc_1xul_ver01   \n",
       "13                                    [Intelligencer]         wvu_jim_ver01   \n",
       "14  [Memphis news scimitar, Sunday illustrated new...        tu_carla_ver01   \n",
       "15  [Combined New York morning newspapers, Combine...      dlc_carril_ver01   \n",
       "16                                [Star, Sunday star]   dlc_2nevelson_ver01   \n",
       "17                                [Star, Sunday star]  dlc_1udaltsova_ver02   \n",
       "18                                 [Omaha Sunday bee]  nbu_azureaster_ver01   \n",
       "19                                [Star, Sunday star]   dlc_2delaunay_ver01   \n",
       "\n",
       "               city               country           county      date  \\\n",
       "0   [San Francisco]            California  [San Francisco]  19041218   \n",
       "1   [San Francisco]            California  [San Francisco]  19031227   \n",
       "2      [Washington]  District of Columbia           [None]  19411123   \n",
       "3      [Washington]  District of Columbia           [None]  19381218   \n",
       "4      [Washington]  District of Columbia           [None]  19480801   \n",
       "5      [Washington]  District of Columbia           [None]  19500423   \n",
       "6         [Chicago]              Illinois    [Cook County]  19120307   \n",
       "7      [Washington]  District of Columbia           [None]  19350728   \n",
       "8        [New York]              New York       [New York]  19070623   \n",
       "9     [New Britain]          Connecticut        [Hartford]  19270422   \n",
       "10    [New Britain]          Connecticut        [Hartford]  19270425   \n",
       "11   [Philadelphia]          Pennsylvania   [Philadelphia]  19200727   \n",
       "12     [Washington]  District of Columbia           [None]  19430411   \n",
       "13       [Wheeling]         West Virginia           [Ohio]  19200103   \n",
       "14        [Memphis]             Tennessee         [Shelby]  19200102   \n",
       "15       [New York]              New York       [New York]  19190615   \n",
       "16     [Washington]  District of Columbia           [None]  19511118   \n",
       "17     [Washington]  District of Columbia           [None]  19420315   \n",
       "18          [Omaha]              Nebraska        [Douglas]  19160917   \n",
       "19     [Washington]  District of Columbia           [None]  19470427   \n",
       "\n",
       "           edition edition_label  end_year  \\\n",
       "0             None                    1913   \n",
       "1             None                    1913   \n",
       "2             None                    1972   \n",
       "3             None                    1972   \n",
       "4             None                    1972   \n",
       "5             None                    1972   \n",
       "6             None                    1917   \n",
       "7             None                    1972   \n",
       "8             None                    1924   \n",
       "9             None                    1976   \n",
       "10            None                    1976   \n",
       "11            None   NIGHT EXTRA      1942   \n",
       "12            None                    1972   \n",
       "13            None                    1961   \n",
       "14            None   4th EDITION      1926   \n",
       "15            None                    1924   \n",
       "16            None                    1972   \n",
       "17            None                    1972   \n",
       "18  [Morning ed.].                    1922   \n",
       "19            None                    1972   \n",
       "\n",
       "                             frequency  ...               publisher  \\\n",
       "0                                Daily  ...   Charles M. Shortridge   \n",
       "1                                Daily  ...   Charles M. Shortridge   \n",
       "2                                Daily  ...     W.D. Wallach & Hope   \n",
       "3                                Daily  ...     W.D. Wallach & Hope   \n",
       "4                                Daily  ...     W.D. Wallach & Hope   \n",
       "5                                Daily  ...     W.D. Wallach & Hope   \n",
       "6   Daily (except Sunday and holidays)  ...            N.D. Cochran   \n",
       "7                                Daily  ...     W.D. Wallach & Hope   \n",
       "8                                Daily  ...        New York Tribune   \n",
       "9                  Daily (except Sun.)  ...         Herald Pub. Co.   \n",
       "10                 Daily (except Sun.)  ...         Herald Pub. Co.   \n",
       "11                 Daily (except Sun.)  ...       Public Ledger Co.   \n",
       "12                               Daily  ...     W.D. Wallach & Hope   \n",
       "13               Daily (except Sunday)  ...  Intelligencer Pub. Co.   \n",
       "14                 Daily (except Sun.)  ...        Gilbert D. Raine   \n",
       "15                               Daily  ...        New York Tribune   \n",
       "16                               Daily  ...     W.D. Wallach & Hope   \n",
       "17                               Daily  ...     W.D. Wallach & Hope   \n",
       "18                               Daily  ...        Edward Rosewater   \n",
       "19                               Daily  ...     W.D. Wallach & Hope   \n",
       "\n",
       "     section_label sequence start_year                   state  \\\n",
       "0                         1       1895            [California]   \n",
       "1                         1       1895            [California]   \n",
       "2                        84       1854  [District of Columbia]   \n",
       "3                       113       1854  [District of Columbia]   \n",
       "4                        76       1854  [District of Columbia]   \n",
       "5                       112       1854  [District of Columbia]   \n",
       "6                         1       1911              [Illinois]   \n",
       "7                        71       1854  [District of Columbia]   \n",
       "8                        44       1866              [New York]   \n",
       "9   Second Section       26       1890           [Connecticut]   \n",
       "10                       12       1890           [Connecticut]   \n",
       "11                       15       1914          [Pennsylvania]   \n",
       "12                       78       1854  [District of Columbia]   \n",
       "13                        9       1903         [West Virginia]   \n",
       "14                       11       1907             [Tennessee]   \n",
       "15                       44       1866              [New York]   \n",
       "16                      140       1854  [District of Columbia]   \n",
       "17                       80       1854  [District of Columbia]   \n",
       "18         PART IV       22       1870              [Nebraska]   \n",
       "19                       83       1854  [District of Columbia]   \n",
       "\n",
       "                                              subject  \\\n",
       "0   [California--San Francisco Bay Area.--fast--(O...   \n",
       "1   [California--San Francisco Bay Area.--fast--(O...   \n",
       "2   [Washington (D.C.)--fast--(OCoLC)fst01204505, ...   \n",
       "3   [Washington (D.C.)--fast--(OCoLC)fst01204505, ...   \n",
       "4   [Washington (D.C.)--fast--(OCoLC)fst01204505, ...   \n",
       "5   [Washington (D.C.)--fast--(OCoLC)fst01204505, ...   \n",
       "6   [Chicago (Ill.)--Newspapers., Illinois--Chicag...   \n",
       "7   [Washington (D.C.)--fast--(OCoLC)fst01204505, ...   \n",
       "8   [New York (N.Y.)--Newspapers., New York (State...   \n",
       "9   [Connecticut--Hartford County.--fast--(OCoLC)f...   \n",
       "10  [Connecticut--Hartford County.--fast--(OCoLC)f...   \n",
       "11  [Pennsylvania--Philadelphia.--fast--(OCoLC)fst...   \n",
       "12  [Washington (D.C.)--fast--(OCoLC)fst01204505, ...   \n",
       "13  [Ohio County (W. Va.)--Newspapers., West Virgi...   \n",
       "14  [Memphis (Tenn.)--Newspapers., Shelby County (...   \n",
       "15  [New York (N.Y.)--Newspapers., New York (State...   \n",
       "16  [Washington (D.C.)--fast--(OCoLC)fst01204505, ...   \n",
       "17  [Washington (D.C.)--fast--(OCoLC)fst01204505, ...   \n",
       "18  [Nebraska--Omaha.--fast--(OCoLC)fst01204995, O...   \n",
       "19  [Washington (D.C.)--fast--(OCoLC)fst01204505, ...   \n",
       "\n",
       "                                   title             title_normal  type  \\\n",
       "0       The San Francisco call. [volume]      san francisco call.  page   \n",
       "1       The San Francisco call. [volume]      san francisco call.  page   \n",
       "2                 Evening star. [volume]            evening star.  page   \n",
       "3                 Evening star. [volume]            evening star.  page   \n",
       "4                 Evening star. [volume]            evening star.  page   \n",
       "5                 Evening star. [volume]            evening star.  page   \n",
       "6                 The day book. [volume]                day book.  page   \n",
       "7                 Evening star. [volume]            evening star.  page   \n",
       "8             New-York tribune. [volume]        new-york tribune.  page   \n",
       "9           New Britain herald. [volume]      new britain herald.  page   \n",
       "10          New Britain herald. [volume]      new britain herald.  page   \n",
       "11       Evening public ledger. [volume]   evening public ledger.  page   \n",
       "12                Evening star. [volume]            evening star.  page   \n",
       "13  The Wheeling intelligencer. [volume]  wheeling intelligencer.  page   \n",
       "14                    The news scimitar.           news scimitar.  page   \n",
       "15            New-York tribune. [volume]        new-york tribune.  page   \n",
       "16                Evening star. [volume]            evening star.  page   \n",
       "17                Evening star. [volume]            evening star.  page   \n",
       "18                      Omaha daily bee.         omaha daily bee.  page   \n",
       "19                Evening star. [volume]            evening star.  page   \n",
       "\n",
       "                                                  url  \n",
       "0   https://chroniclingamerica.loc.gov/lccn/sn8506...  \n",
       "1   https://chroniclingamerica.loc.gov/lccn/sn8506...  \n",
       "2   https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "3   https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "4   https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "5   https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "6   https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "7   https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "8   https://chroniclingamerica.loc.gov/lccn/sn8303...  \n",
       "9   https://chroniclingamerica.loc.gov/lccn/sn8201...  \n",
       "10  https://chroniclingamerica.loc.gov/lccn/sn8201...  \n",
       "11  https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "12  https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "13  https://chroniclingamerica.loc.gov/lccn/sn8609...  \n",
       "14  https://chroniclingamerica.loc.gov/lccn/sn9806...  \n",
       "15  https://chroniclingamerica.loc.gov/lccn/sn8303...  \n",
       "16  https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "17  https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "18  https://chroniclingamerica.loc.gov/lccn/sn9902...  \n",
       "19  https://chroniclingamerica.loc.gov/lccn/sn8304...  \n",
       "\n",
       "[20 rows x 28 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "In this exercise, you queried an API from Chronicling America and pulled in files that included the search term \"poetry.\" Those files, then, were cleaned and made slightly more tidy by highlighting the \"keys\" to the dictionary, and then taking one small section of the dictionary and turning it into a dataframe. In a markdown section, look over what you have done, and try changing the search *parameter* at the top of the exercise. What changes when you re run the activity? What is \"messy\" about the file that makes it hard to work with? What is \"clean\" about the file that makes it easier to work with? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I reran using \"prose\" as the parameter.  The messiness comes with brackets around some of the values and some of the cells having null values.\n",
    "\n",
    "The only significant change is in the number of items.  This highlights one of the huge advantages of the clean file; it is easy to spot issues, easy to read, easy to visualize."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
